<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Kubectl管理多集群</title>
    <url>/2021/05/07/Kubectl%E7%AE%A1%E7%90%86%E5%A4%9A%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><ul>
<li>当有多个Kubernetes集群需要管理时，我们需要在不同客户端之间切换，这个过程比较繁琐，幸运的是Kubectl提供了在多个Kubernetes集群间切换的能力，所以该篇文章便是实践kubectl管理多个k8s集群</li>
<li>梳理了官方文档以及各种博客实践文章，感觉十分繁琐，所以在次记录一下实现方案</li>
</ul>
<h4 id="准备："><a href="#准备：" class="headerlink" title="准备："></a>准备：</h4><ul>
<li>请先阅读官方文档：<a href="https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/">https://kubernetes.io/zh/docs/tasks/access-application-cluster/configure-access-multiple-clusters/</a></li>
<li>已经拥有多个Kubernetes集群</li>
</ul>
<h4 id="Kubectl多个集群间切换"><a href="#Kubectl多个集群间切换" class="headerlink" title="Kubectl多个集群间切换"></a>Kubectl多个集群间切换</h4><h5 id="合并Kubeconfig文件"><a href="#合并Kubeconfig文件" class="headerlink" title="合并Kubeconfig文件"></a>合并Kubeconfig文件</h5><ul>
<li>将多个集群的<code>$home/.kube/config</code>文件拷贝到一起，并修改文件中 cluster name，context关联关系名称，user name，因为多个集群的名称相同</li>
<li>config1详细信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node-01 .kube]# cat $HOME/.kube/config1</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Config</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    api-version: v1</span><br><span class="line">    certificate-authority-data: xxxxxxx</span><br><span class="line">    server: &quot;https://172.20.8.113:6443&quot;</span><br><span class="line">  name: &quot;cn-k8s&quot;</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: &quot;cn-k8s&quot;</span><br><span class="line">    user: &quot;kube-admin-local&quot;</span><br><span class="line">  name: &quot;cn-k8s&quot;</span><br><span class="line">current-context: &quot;cn-k8s&quot;</span><br><span class="line">users:</span><br><span class="line">- name: &quot;kube-admin-local&quot;</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxxxxx</span><br><span class="line">    client-key-data: xxxxxx</span><br></pre></td></tr></table></figure>
<ul>
<li>config2详细信息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@node-01 .kube]# cat $HOME/.kube/config2</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Config</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    api-version: v1</span><br><span class="line">    certificate-authority-data: xxxxxx</span><br><span class="line">    server: &quot;https://172.19.8.113:6443&quot;</span><br><span class="line">  name: &quot;jp-k8s&quot;</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: &quot;jp-k8s&quot;</span><br><span class="line">    user: &quot;kube-admin-local&quot;</span><br><span class="line">  name: &quot;jp-k8s&quot;</span><br><span class="line">current-context: &quot;jp-k8s&quot;</span><br><span class="line">users:</span><br><span class="line">- name: &quot;kube-admin-local&quot;</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: xxxxxx</span><br><span class="line">    client-key-data: xxxxxx</span><br></pre></td></tr></table></figure>
<ul>
<li>执行如下命令进行合并</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> <span class="variable">$HOME</span>/.kube/config</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> KUBECONFIG=config1:config2 kubectl config view --flatten &gt; <span class="variable">$HOME</span>/.kube/config</span></span><br><span class="line">- 合并完成后，便可使用kubectl config use-context xxxx 来切换集群了</span><br></pre></td></tr></table></figure>
<h5 id=""><a href="#" class="headerlink" title=""></a></h5><h4 id="设置kubeconfig管理集群中指定namespace"><a href="#设置kubeconfig管理集群中指定namespace" class="headerlink" title="设置kubeconfig管理集群中指定namespace"></a>设置kubeconfig管理集群中指定namespace</h4><h5 id="方法一：使用CSR创建账户"><a href="#方法一：使用CSR创建账户" class="headerlink" title="方法一：使用CSR创建账户"></a>方法一：使用CSR创建账户</h5><ul>
<li><a href="https://k8s.imroc.io/security/user/create-user-using-csr-api/">https://k8s.imroc.io/security/user/create-user-using-csr-api/</a></li>
</ul>
<h5 id="方法二：创建客户端证书并绑定角色"><a href="#方法二：创建客户端证书并绑定角色" class="headerlink" title="方法二：创建客户端证书并绑定角色"></a>方法二：创建客户端证书并绑定角色</h5><ul>
<li><a href="https://blog.51cto.com/u_11954248/2481403">https://blog.51cto.com/u_11954248/2481403</a></li>
</ul>
<h5 id="方法三：使用RBAC实现kubeconfig管理指定namespace"><a href="#方法三：使用RBAC实现kubeconfig管理指定namespace" class="headerlink" title="方法三：使用RBAC实现kubeconfig管理指定namespace"></a>方法三：使用RBAC实现kubeconfig管理指定namespace</h5><ul>
<li><p>创建sa</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create ns linux</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create serviceaccount antmove -n linux</span></span><br></pre></td></tr></table></figure></li>
<li><p>创建role</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">linux</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">linux-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;*&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">    <span class="comment">#verbs: [&quot;*&quot;]</span></span><br><span class="line">    <span class="comment">##RO-Role</span></span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]       </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;extensions&quot;</span>, <span class="string">&quot;apps&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;deployments&quot;</span>]</span><br><span class="line">    <span class="comment">#verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</span></span><br><span class="line">    <span class="comment">##RO-Role</span></span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">role-bind-linux</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">linux</span></span><br><span class="line"><span class="attr">subjects:</span> </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">antmove</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">linux</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">linux-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></li>
<li><p>获取token</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get secret antmoveh-token-fgf5v -n linux -o jsonpath=&#123;.data.token&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>将token写入kubeconfig文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl config set-credentials <span class="built_in">test</span> --token=$(kubectl get secret laomao-token-x7dxp -n linux39 -o jsonpath=&#123;.data.token&#125;)</span></span><br><span class="line">- 这里指定了namespace,当切换到这个context时，kubectl默认ns就会是linux</span><br><span class="line">- 如果想管理多个ns,则在rabc处设置ns管理规则</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config set-context <span class="built_in">test</span> --cluster=kubernetes --namespace=linux --user=<span class="built_in">test</span></span></span><br><span class="line">- 切换到执行context</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config use-context <span class="built_in">test</span></span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubeletRunInContainer</title>
    <url>/2021/03/23/KubeletRunInContainer/</url>
    <content><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul>
<li>Kubernetes服务组件包括<code>kube-apiserver kube-controller-manager kube-scheduler kubelet</code> ，除kubelet外其他组件均已容器化运行，使用命令<code>kubectl get pods -n kube-system</code>可观察到运行的容器组件</li>
<li>本篇文章主要讲述如何在容器中运行kubelet</li>
</ul>
<h4 id="Kubelet容器化部署"><a href="#Kubelet容器化部署" class="headerlink" title="Kubelet容器化部署"></a>Kubelet容器化部署</h4><blockquote>
<ul>
<li>kubelet容器化部署并不鲜见，可以搜索到各种相关示例如：<a href="https://github.com/kubernetes-retired/kubernetes-anywhere/blob/master/phase2/ignition/vanilla/kubelet.service">https://github.com/kubernetes-retired/kubernetes-anywhere/blob/master/phase2/ignition/vanilla/kubelet.service</a></li>
</ul>
</blockquote>
<h5 id="选择kubelet容器"><a href="#选择kubelet容器" class="headerlink" title="选择kubelet容器"></a>选择kubelet容器</h5><ul>
<li><p>Kubernetes官方镜像<code>googlecontainersmirrors/hyperkube-amd64</code>已经将各个组件的二进制文件收集到镜像中，上述仓库为谷歌镜像仓库，原镜像地址为<code>gcr.io/google-containers/hyperkube-amd64</code></p>
</li>
<li><p>从<code>https://console.cloud.google.com/gcr/images/google-containers</code> 搜索<code>hyperkube-amd64</code>可获取原镜像地址</p>
</li>
<li><p>Kubernetes 1.19版本以后，不在构建<code>hyperkube-adm64</code>超级镜像，稍后会介绍构建我们自己的kubelet</p>
</li>
</ul>
<h5 id="Master节点部署"><a href="#Master节点部署" class="headerlink" title="Master节点部署"></a>Master节点部署</h5><ul>
<li><p>Kubernetes Master节点使用kubeadm工具快速部署：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm init --kubernetes-version=v1.19.4 --apiserver-advertise-address=192.168.56.120 --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure>
<h5 id="Worker节点"><a href="#Worker节点" class="headerlink" title="Worker节点"></a>Worker节点</h5></li>
<li><p>Kubelet正常启动，主要有以下几个关键点</p>
<ul>
<li>生成客户端证书</li>
<li>创建Kubelet配置文件</li>
<li>启动Kubelet</li>
</ul>
</li>
<li><p>生成客户端证书</p>
<ul>
<li><p>将Master节点 目录<code>/etc/kubernetes/pki</code>下根证书<code>ca.crt ca.key</code>复制到Worker节点 <code>/etc/kubernetes</code>目录下，并将<code>ca.crt</code>复制到<code>/etc/kubernetes/pki</code>目录下</p>
</li>
<li><p>使用如下命令创建客户端证书</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubeadm init phase kubeconfig kubelet --cert-dir=/etc/kubernetes --kubeconfig-dir=/etc/kubernetes --apiserver-advertise-address=192.168.56.120 --kubernetes-version=v1.19.4</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>创建配置文件</p>
<ul>
<li><p>在<code>/etc/kubernetes</code>目录下创建kubelet_settings.yml，内容如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">authentication:</span></span><br><span class="line">  <span class="attr">anonymous:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheTTL:</span> <span class="string">0s</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">x509:</span></span><br><span class="line">    <span class="attr">clientCAFile:</span> <span class="string">/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"><span class="attr">authorization:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">Webhook</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheAuthorizedTTL:</span> <span class="string">0s</span></span><br><span class="line">    <span class="attr">cacheUnauthorizedTTL:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">cgroupDriver:</span> <span class="string">systemd</span></span><br><span class="line"><span class="attr">clusterDNS:</span></span><br><span class="line"><span class="bullet">-</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.10</span></span><br><span class="line"><span class="attr">clusterDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">cpuManagerReconcilePeriod:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">evictionPressureTransitionPeriod:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">fileCheckFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">healthzBindAddress:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"><span class="attr">healthzPort:</span> <span class="number">10248</span></span><br><span class="line"><span class="attr">httpCheckFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">imageMinimumGCAge:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeletConfiguration</span></span><br><span class="line"><span class="attr">logging:</span> &#123;&#125;</span><br><span class="line"><span class="attr">nodeStatusReportFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">nodeStatusUpdateFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">rotateCertificates:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">runtimeRequestTimeout:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">staticPodPath:</span> <span class="string">/etc/kubernetes/manifests</span></span><br><span class="line"><span class="attr">streamingConnectionIdleTimeout:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">syncFrequency:</span> <span class="string">0s</span></span><br><span class="line"><span class="attr">volumeStatsAggPeriod:</span> <span class="string">0s</span> </span><br></pre></td></tr></table></figure></li>
<li><p>当然也可以定制化配置文件内容</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeletConfiguration</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">authentication:</span></span><br><span class="line">  <span class="attr">anonymous:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheTTL:</span> <span class="string">2m0s</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">x509:</span></span><br><span class="line">    <span class="attr">clientCAFile:</span> <span class="string">/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"><span class="attr">authorization:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">Webhook</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheAuthorizedTTL:</span> <span class="string">5m0s</span></span><br><span class="line">    <span class="attr">cacheUnauthorizedTTL:</span> <span class="string">30s</span></span><br><span class="line"><span class="attr">cgroupDriver:</span> <span class="string">systemd</span></span><br><span class="line"><span class="attr">clusterDNS:</span></span><br><span class="line"><span class="bullet">-</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.10</span></span><br><span class="line"><span class="attr">clusterDomain:</span> <span class="string">cluster.local</span></span><br><span class="line"><span class="attr">configMapAndSecretChangeDetectionStrategy:</span> <span class="string">Watch</span></span><br><span class="line"><span class="attr">containerLogMaxFiles:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">containerLogMaxSize:</span> <span class="string">10Mi</span></span><br><span class="line"><span class="attr">contentType:</span> <span class="string">application/vnd.kubernetes.protobuf</span></span><br><span class="line"><span class="attr">cpuCFSQuota:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">cpuCFSQuotaPeriod:</span> <span class="string">100ms</span></span><br><span class="line"><span class="attr">cpuManagerPolicy:</span> <span class="string">none</span></span><br><span class="line"><span class="attr">cpuManagerReconcilePeriod:</span> <span class="string">10s</span></span><br><span class="line"><span class="attr">enableControllerAttachDetach:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">enableDebuggingHandlers:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">eventBurst:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">eventRecordQPS:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">evictionHard:</span></span><br><span class="line">  <span class="attr">imagefs.available:</span> <span class="number">15</span><span class="string">%</span></span><br><span class="line">  <span class="attr">memory.available:</span> <span class="string">200Mi</span></span><br><span class="line">  <span class="attr">nodefs.available:</span> <span class="number">10</span><span class="string">%</span></span><br><span class="line">  <span class="attr">nodefs.inodesFree:</span> <span class="number">10</span><span class="string">%</span></span><br><span class="line"><span class="attr">evictionPressureTransitionPeriod:</span> <span class="string">5m0s</span></span><br><span class="line"><span class="attr">failSwapOn:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">fileCheckFrequency:</span> <span class="string">20s</span></span><br><span class="line"><span class="attr">hairpinMode:</span> <span class="string">promiscuous-bridge</span></span><br><span class="line"><span class="attr">healthzBindAddress:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">healthzPort:</span> <span class="number">10248</span></span><br><span class="line"><span class="attr">httpCheckFrequency:</span> <span class="string">20s</span></span><br><span class="line"><span class="attr">imageGCHighThresholdPercent:</span> <span class="number">85</span></span><br><span class="line"><span class="attr">imageGCLowThresholdPercent:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">imageMinimumGCAge:</span> <span class="string">2m0s</span></span><br><span class="line"><span class="attr">iptablesDropBit:</span> <span class="number">15</span></span><br><span class="line"><span class="attr">iptablesMasqueradeBit:</span> <span class="number">14</span></span><br><span class="line"><span class="attr">kubeAPIBurst:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">kubeAPIQPS:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">makeIPTablesUtilChains:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">maxOpenFiles:</span> <span class="number">1000000</span></span><br><span class="line"><span class="attr">maxPods:</span> <span class="number">110</span> </span><br><span class="line"><span class="attr">nodeLeaseDurationSeconds:</span> <span class="number">40</span></span><br><span class="line"><span class="attr">nodeStatusReportFrequency:</span> <span class="string">1m0s</span></span><br><span class="line"><span class="attr">nodeStatusUpdateFrequency:</span> <span class="string">10s</span></span><br><span class="line"><span class="attr">oomScoreAdj:</span> <span class="number">-999</span></span><br><span class="line"><span class="attr">podPidsLimit:</span> <span class="number">-1</span></span><br><span class="line"><span class="attr">port:</span> <span class="number">10250</span></span><br><span class="line"><span class="attr">registryBurst:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">registryPullQPS:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">resolvConf:</span> <span class="string">/etc/resolv.conf</span></span><br><span class="line"><span class="attr">rotateCertificates:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">runtimeRequestTimeout:</span> <span class="string">2m0s</span></span><br><span class="line"><span class="attr">serializeImagePulls:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">staticPodPath:</span> <span class="string">/etc/kubernetes/manifests</span></span><br><span class="line"><span class="attr">streamingConnectionIdleTimeout:</span> <span class="string">4h0m0s</span></span><br><span class="line"><span class="attr">syncFrequency:</span> <span class="string">1m0s</span></span><br><span class="line"><span class="attr">volumeStatsAggPeriod:</span> <span class="string">1m0s</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>启动Kubelet</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=kubelet --net=host --pid=host --privileged \ </span><br><span class="line">-v /dev:/dev -v /sys:/sys:ro -v /var/run:/var/run:rw \</span><br><span class="line">-v /var/lib/calico:/var/lib/calico:ro \ </span><br><span class="line">-v /var/lib/docker/:/var/lib/docker:rw \ </span><br><span class="line">-v /var/lib/kubelet/:/var/lib/kubelet:shared \ </span><br><span class="line">-v /var/log:/var/log:shared -v /opt/cni/bin:/opt/cni/bin \</span><br><span class="line">-v /etc/cni/:/etc/cni -v /etc/kubernetes:/etc/kubernetes:ro \</span><br><span class="line">googlecontainersmirrors/hyperkube-amd64:v1.19.0-alpha.0 \</span><br><span class="line">kubelet --hostname-override=192.168.56.121 \</span><br><span class="line">--config=/etc/kubernetes/kubelet_settings.yml \ </span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf \</span><br><span class="line">--register-node=true --network-plugin=cni</span><br></pre></td></tr></table></figure>
<h4 id="构建Kubelet镜像"><a href="#构建Kubelet镜像" class="headerlink" title="构建Kubelet镜像"></a>构建Kubelet镜像</h4></li>
<li><p>在Kubernetes 1.19版本之后便不再提供<code>googlecontainersmirrors/hyperkube-amd64</code>镜像，可使用如下<code>Dockerfile</code>构建镜像</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> antmoveh/debian-hyperkube-base-amd64:v1.<span class="number">1.3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> version=v1.<span class="number">20.4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> https://storage.googleapis.com/kubernetes-release/release/<span class="variable">$&#123;version&#125;</span>/bin/linux/amd64/kubelet /usr/<span class="built_in">local</span>/bin</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x /usr/<span class="built_in">local</span>/bin/kubelet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;kubelet&quot;</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># docker build --build-arg version=v1.20.4 -t kubectl:tag .</span></span><br></pre></td></tr></table></figure>
<ul>
<li>如果有将<code>kube-apiserver</code>等组件加入容器的需求，可以依次添加二进制文件到镜像内</li>
<li><code>antmoveh/debian-hyperkube-base-amd64:v1.1.3</code>镜像为<code>k8s.gcr.io/build-image/debian-hyperkube-base-amd64:v1.1.3</code></li>
<li>参考hyperkube镜像构建<a href="https://github.com/kubernetes/kubernetes/tree/release-1.18/cluster/images/hyperkube">https://github.com/kubernetes/kubernetes/tree/release-1.18/cluster/images/hyperkube</a></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Etcd</title>
    <url>/2021/06/15/KuberentesEtcd/</url>
    <content><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul>
<li>有时候需要查看下Kubernetes在etcd中存储数据，每次去翻看相关文章总觉得麻烦，所以在此记录一下操作etcd的方法</li>
</ul>
<h4 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h4><ul>
<li>准备一个Kubernetes集群</li>
</ul>
<h4 id="etcd实践"><a href="#etcd实践" class="headerlink" title="etcd实践"></a>etcd实践</h4><ul>
<li>首先进入etcd所在容器</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods -n kube-system | grep etcd</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> -it etcd-192.168.56.120 -n kube-system sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> etcdctl version</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 有的etcd容器内没有各种命令，将etcdctl cp到宿主机</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 小插曲containerd貌似不支持cp命令，我找到镜像文件复制了出来</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/14/fs/usr/<span class="built_in">local</span>/bin/etcdctl /usr/<span class="built_in">local</span>/bin</span></span><br></pre></td></tr></table></figure>
<ul>
<li>连接指定etcd集群</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">alias</span> ctl=<span class="string">&#x27;ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key&#x27;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">alias</span> ctl=<span class="string">&#x27;ETCDCTL_API=3 etcdctl --endpoints 10.2.0.9:2379,10.0.0.3:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key&#x27;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">alias</span> ctl=<span class="string">&#x27;ETCDCTL_API=3 etcdctl --endpoints 192.168.56.120:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key&#x27;</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>操作命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取所有key</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get <span class="string">&quot;&quot;</span> --prefix --keys-only</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 namespaces信息</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get /registry/namespaces/default -w json | jq.</span> </span><br><span class="line">&#123;</span><br><span class="line">  &quot;header&quot;: &#123;</span><br><span class="line">    &quot;cluster_id&quot;: 14378179553578170000,</span><br><span class="line">    &quot;member_id&quot;: 15647210633225947000,</span><br><span class="line">    &quot;revision&quot;: 9926,</span><br><span class="line">    &quot;raft_term&quot;: 2</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;kvs&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;key&quot;: &quot;L3JlZ2lzdHJ5L25hbWVzcGFjZXMvZGVmYXVsdA==&quot;,</span><br><span class="line">      &quot;create_revision&quot;: 191,</span><br><span class="line">      &quot;mod_revision&quot;: 191,</span><br><span class="line">      &quot;version&quot;: 1,</span><br><span class="line">      &quot;value&quot;: &quot;azhzAAoPCgJ2MRIJTmFtZXNwYWNlErIBCpcBCgdkZWZhdWx0EgAaACIAKiRhM2Y5NzUxNC0zZmExLTQyZDgtYmE4Yi0zMDM1M2I0MmFkMzQyADgAQggIv7qghgYQAHoAigFPCg5rdWJlLWFwaXNlcnZlchIGVXBkYXRlGgJ2MSIICL+6oIYGEAAyCEZpZWxkc1YxOh0KG3siZjpzdGF0dXMiOnsiZjpwaGFzZSI6e319fRIMCgprdWJlcm5ldGVzGggKBkFjdGl2ZRoAIgA=&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;count&quot;: 1</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看所有namespaces</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get /registry/namespaces --prefix -w json | python -m json.tool</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Key是经过base64编码，需要解码后才能看到实际值</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> L3JlZ2lzdHJ5L25hbWVzcGFjZXMvZGVmYXVsdA== | base64 -d</span></span><br><span class="line">/registry/namespaces/default</span><br></pre></td></tr></table></figure>
<ul>
<li>操作实验</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建ns</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create ns <span class="built_in">test</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd中查看</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get /registry/namespaces/ --prefix --keys-only</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建pod</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl run busybox --image=busybox:1.28 sleep 1000 -n <span class="built_in">test</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 首先查看一下和<span class="built_in">test</span>命名空间有关的资源</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如下输出可以观察到创建一个ns实质上还会创建configmap/secrets/serviceaccounts等events计时器结束后会自动消失</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get <span class="string">&quot;&quot;</span> --prefix --keys-only |grep <span class="built_in">test</span></span></span><br><span class="line">/registry/configmaps/test/kube-root-ca.crt</span><br><span class="line">/registry/events/test/busybox.1688ae2d618cd375</span><br><span class="line">/registry/events/test/busybox.1688ae2d7aeee09f</span><br><span class="line">/registry/events/test/busybox.1688ae2d98c3b280</span><br><span class="line">/registry/events/test/busybox.1688ae2d9b72ad6e</span><br><span class="line">/registry/namespaces/test</span><br><span class="line">/registry/pods/test/busybox</span><br><span class="line">/registry/secrets/test/default-token-dhg64</span><br><span class="line">/registry/serviceaccounts/test/default</span><br><span class="line"><span class="meta">#</span><span class="bash"> 观察一个events</span></span><br><span class="line">[root@192 ~]# ctl get /registry/events/test/busybox.1688ae2d618cd375 -w json | jq .</span><br><span class="line">&#123;</span><br><span class="line">  &quot;header&quot;: &#123;</span><br><span class="line">    &quot;cluster_id&quot;: 14378179553578170000,</span><br><span class="line">    &quot;member_id&quot;: 15647210633225947000,</span><br><span class="line">    &quot;revision&quot;: 12141,</span><br><span class="line">    &quot;raft_term&quot;: 2</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;kvs&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;key&quot;: &quot;L3JlZ2lzdHJ5L2V2ZW50cy90ZXN0L2J1c3lib3guMTY4OGFlMmQ2MThjZDM3NQ==&quot;,</span><br><span class="line">      &quot;create_revision&quot;: 11200,</span><br><span class="line">      &quot;mod_revision&quot;: 11200,</span><br><span class="line">      &quot;version&quot;: 1,</span><br><span class="line">      &quot;value&quot;: &quot;azhzAAoLCgJ2MRIFRXZlbnQS9gQKiQMKGGJ1c3lib3guMTY4OGFlMmQ2MThjZDM3NRIAGgR0ZXN0IgAqJDFiZjQyYzZkLWQ4YTQtNGM2Zi1iMjE5LWNlNzE4ZDBhY2EzMjIAOABCCAinlqGGBhAAegCKAasCCg5rdWJlLXNjaGVkdWxlchIGVXBkYXRlGhBldmVudHMuazhzLmlvL3YxIggIp5ahhgYQADIIRmllbGRzVjE66gEK5wF7ImY6YWN0aW9uIjp7fSwiZjpldmVudFRpbWUiOnt9LCJmOm5vdGUiOnt9LCJmOnJlYXNvbiI6e30sImY6cmVnYXJkaW5nIjp7ImY6YXBpVmVyc2lvbiI6e30sImY6a2luZCI6e30sImY6bmFtZSI6e30sImY6bmFtZXNwYWNlIjp7fSwiZjpyZXNvdXJjZVZlcnNpb24iOnt9LCJmOnVpZCI6e319LCJmOnJlcG9ydGluZ0NvbnRyb2xsZXIiOnt9LCJmOnJlcG9ydGluZ0luc3RhbmNlIjp7fSwiZjp0eXBlIjp7fX0SRwoDUG9kEgR0ZXN0GgdidXN5Ym94IiRjMjAwZWZlNi1hM2Y0LTQ3NzQtODFhZS1kY2FiNDViNDRlZjYqAnYxMgUxMTE5ODoAGglTY2hlZHVsZWQiNFN1Y2Nlc3NmdWxseSBhc3NpZ25lZCB0ZXN0L2J1c3lib3ggdG8gMTkyLjE2OC41Ni4xMjEqBAoAEgAyADoAQABKBk5vcm1hbFIMCKeWoYYGEJj8p54CYgdCaW5kaW5nchFkZWZhdWx0LXNjaGVkdWxlcnogZGVmYXVsdC1zY2hlZHVsZXItMTkyLjE2OC41Ni4xMjAaACIA&quot;,</span><br><span class="line">      &quot;lease&quot;: 5317477984281219000</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;count&quot;: 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 找一个具体的events查看一下他的内容，value值是经过Protocol Buffers序列化后的，用strings转换一下就可以看到具体内容</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get /registry/events/<span class="built_in">test</span>/busybox.1688ae2d618cd375 --print-value-only | strings</span></span><br><span class="line">Event</span><br><span class="line">busybox.1688ae2d618cd375</span><br><span class="line">test&quot;</span><br><span class="line">*$1bf42c6d-d8a4-4c6f-b219-ce718d0aca322</span><br><span class="line">kube-scheduler</span><br><span class="line">Update</span><br><span class="line">events.k8s.io/v1&quot;</span><br><span class="line">FieldsV1:</span><br><span class="line">&#123;&quot;f:action&quot;:&#123;&#125;,&quot;f:eventTime&quot;:&#123;&#125;,&quot;f:note&quot;:&#123;&#125;,&quot;f:reason&quot;:&#123;&#125;,&quot;f:regarding&quot;:&#123;&quot;f:apiVersion&quot;:&#123;&#125;,&quot;f:kind&quot;:&#123;&#125;,&quot;f:name&quot;:&#123;&#125;,&quot;f:namespace&quot;:&#123;&#125;,&quot;f:resourceVersion&quot;:&#123;&#125;,&quot;f:uid&quot;:&#123;&#125;&#125;,&quot;f:reportingController&quot;:&#123;&#125;,&quot;f:reportingInstance&quot;:&#123;&#125;,&quot;f:type&quot;:&#123;&#125;&#125;</span><br><span class="line">test</span><br><span class="line">busybox&quot;$c200efe6-a3f4-4774-81ae-dcab45b44ef6*</span><br><span class="line">11198:</span><br><span class="line">        Scheduled&quot;4Successfully assigned test/busybox to 192.168.56.121*</span><br><span class="line">NormalR</span><br><span class="line">Bindingr</span><br><span class="line">default-schedulerz default-scheduler-192.168.56.120</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意events有一个lease，这个是一个计时器的ID，可以用如下方法找到</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl lease list</span></span><br><span class="line">found 5 leases</span><br><span class="line">49cb7a0db20ae022</span><br><span class="line">49cb7a0db20ae05f</span><br><span class="line">49cb7a0db20acf1e</span><br><span class="line">49cb7a0db20acf2b</span><br><span class="line">49cb7a0db20ad0b3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 找到详细的计时器信息，这个一个一个打开来找的，刚创建的排在下边。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 多个相近时间events会共用一个计时器，这是为了减少etcd中lease的数量提高处理性能，总觉得这个设计是专为了k8s这种场景，不重要的消息不要求十分精确</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl lease timetolive 49cb7a0db20ad0b3 -w=json | jq .</span>                </span><br><span class="line">&#123;</span><br><span class="line">  &quot;cluster_id&quot;: 14378179553578170000,</span><br><span class="line">  &quot;member_id&quot;: 15647210633225947000,</span><br><span class="line">  &quot;revision&quot;: 12249,</span><br><span class="line">  &quot;raft_term&quot;: 2,</span><br><span class="line">  &quot;id&quot;: 5317477984281219000,</span><br><span class="line">  &quot;ttl&quot;: 2861,</span><br><span class="line">  &quot;granted-ttl&quot;: 3660,</span><br><span class="line">  &quot;keys&quot;: null</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>总结一下：</p>
<ul>
<li>创建ns会在相应命名空间下创建onfigmap/secrets/serviceaccounts资源</li>
<li>kubernetes会将数据全存储在/registry前缀下，因为ectd v3 key是平铺的，只是看起来有层级结构</li>
<li>/registry下一层是API对象类型，比如<code>/registry/namespace/test</code> <code>/registry/pods/test/buxybox</code> </li>
<li>etcd中key都是用base64编码的，value是Protocol Buffers序列化后的值</li>
</ul>
</li>
<li><p>危险操作</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在etcd 中直接删除ns</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl del /registry/namespaces/<span class="built_in">test</span></span></span><br><span class="line">1</span><br><span class="line"><span class="meta">$</span><span class="bash"> ctl get <span class="string">&quot;&quot;</span> --prefix --keys-only |grep <span class="built_in">test</span></span></span><br><span class="line">/registry/configmaps/test/kube-root-ca.crt</span><br><span class="line">/registry/events/test/busybox.1688ae2d618cd375</span><br><span class="line">/registry/events/test/busybox.1688ae2d7aeee09f</span><br><span class="line">/registry/events/test/busybox.1688ae2d98c3b280</span><br><span class="line">/registry/events/test/busybox.1688ae2d9b72ad6e</span><br><span class="line">/registry/events/test/nginx.1688ae1f81f9a9a2</span><br><span class="line">/registry/events/test/nginx.1688ae1f9d42fcad</span><br><span class="line">/registry/events/test/nginx.1688ae2974388590</span><br><span class="line">/registry/events/test/nginx.1688ae297439626b</span><br><span class="line">/registry/pods/test/busybox</span><br><span class="line">/registry/secrets/test/default-token-dhg64</span><br><span class="line">/registry/serviceaccounts/test/default</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在k8s中查看ns下相关资源，发现还可以看到，所以暴力删除资源时要注意清理与其相关的所有资源</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods -A|grep <span class="built_in">test</span></span></span><br><span class="line">test          busybox                                  1/1     Running   1          33m</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get sa -A|grep <span class="built_in">test</span></span>    </span><br><span class="line">test              default                              1         46m</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get configmaps -A|grep <span class="built_in">test</span></span>    </span><br><span class="line">test              kube-root-ca.crt                     1      47m</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes自定义调度器开发</title>
    <url>/2021/03/07/Kubernetes%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E5%BA%A6%E5%99%A8%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h4 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h4><ul>
<li><code>kube-scheduler</code> 是 kubernetes 的核心组件之一，主要负责整个集群资源的调度功能，根据特定的调度算法和策略，将 Pod 调度到最优的工作节点上面去，从而更加合理、更加充分的利用集群的资源，这也是我们选择使用 kubernetes 一个非常重要的理由。如果一门新的技术不能帮助企业节约成本、提供效率，我相信是很难推进的。 </li>
<li>默认情况下，<code>kube-scheduler</code> 提供的默认调度器能够满足我们绝大多数的要求，我们前面和大家接触的示例也基本上用的默认的策略，都可以保证我们的 Pod 可以被分配到资源充足的节点上运行。但是在实际的线上项目中，可能我们自己会比 kubernetes 更加了解我们自己的应用，比如我们希望一个 Pod 只能运行在特定的几个节点上，或者这几个节点只能用来运行特定类型的应用，这就需要我们的调度器能够可控。</li>
<li><code>kube-scheduler</code> 的主要作用就是根据特定的调度算法和调度策略将 Pod 调度到合适的 Node 节点上去，是一个独立的二进制程序，启动之后会一直监听 API Server，获取到 <code>PodSpec.NodeName</code> 为空的 Pod，对每个 Pod 都会创建一个 binding。</li>
<li>本篇文章并不是一篇Scheduler Framework介绍及简要示例文章，而是Scheduler Framework开发细节，所以有必要先阅读推荐的文章</li>
</ul>
<h4 id="调度器简介"><a href="#调度器简介" class="headerlink" title="调度器简介"></a>调度器简介</h4><p>一般来说，我们有4种扩展 Kubernetes 调度器的方法。</p>
<ul>
<li>一种方法就是直接 clone 官方的 kube-scheduler 源代码，在合适的位置直接修改代码，然后重新编译运行修改后的程序，当然这种方法是最不建议使用的，也不实用，因为需要花费大量额外的精力来和上游的调度程序更改保持一致。</li>
<li>第二种方法就是和默认的调度程序一起运行独立的调度程序，默认的调度器和我们自定义的调度器可以通过 Pod 的 <code>spec.schedulerName</code> 来覆盖各自的 Pod，默认是使用 default 默认的调度器，但是多个调度程序共存的情况下也比较麻烦，比如当多个调度器将 Pod 调度到同一个节点的时候，可能会遇到一些问题，因为很有可能两个调度器都同时将两个 Pod 调度到同一个节点上去，但是很有可能其中一个 Pod 运行后其实资源就消耗完了，并且维护一个高质量的自定义调度程序也不是很容易的，因为我们需要全面了解默认的调度程序，整体 Kubernetes 的架构知识以及各种 Kubernetes API 对象的各种关系或限制。</li>
<li>第三种方法是<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md">调度器扩展程序</a>，这个方案目前是一个可行的方案，可以和上游调度程序兼容，所谓的调度器扩展程序其实就是一个可配置的 Webhook 而已，里面包含 <code>过滤器</code> 和 <code>优先级</code> 两个端点，分别对应调度周期中的两个主要阶段（过滤和打分）。</li>
<li>第四种方法是通过调度框架（Scheduling Framework），Kubernetes v1.15 版本中引入了可插拔架构的调度框架，使得定制调度器这个任务变得更加的容易。调库框架向现有的调度器中添加了一组插件化的 API，该 API 在保持调度程序“核心”简单且易于维护的同时，使得大部分的调度功能以插件的形式存在，而且在我们现在的 v1.16 版本中上面的 <code>调度器扩展程序</code> 也已经被废弃了，所以以后调度框架才是自定义调度器的核心方式。</li>
</ul>
<p>如上所述可以看到Scheduling Framework才是自定义调度器的核心方式</p>
<ul>
<li>关于扩展调度器介绍文章比较多，在此选取了几篇参考文章，可以综合多篇文章更加了解Kubernetes扩展调度器</li>
<li>自定义 Kubernetes 调度器：<a href="https://www.qikqiak.com/post/custom-kube-scheduler/">https://www.qikqiak.com/post/custom-kube-scheduler/</a> </li>
<li>进击的kubernetes调度系统：<a href="https://cloud.tencent.com/developer/news/656313">https://cloud.tencent.com/developer/news/656313</a></li>
<li>Kubernetes 文档：<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/scheduling-framework/">https://kubernetes.io/zh/docs/concepts/scheduling-eviction/scheduling-framework/</a> </li>
<li>Kubernetes Scheduler Framework 扩展:：<a href="https://developer.aliyun.com/article/756016">https://developer.aliyun.com/article/756016</a> </li>
<li>Scheduler Framework 初探:：<a href="https://zhuanlan.zhihu.com/p/98853029">https://zhuanlan.zhihu.com/p/98853029</a> </li>
<li>浅谈 Kubernetes Scheduling-Framework 插件的实现:：<a href="https://www.infoq.cn/article/d1sciembtxrkvmgvf9b1">https://www.infoq.cn/article/d1sciembtxrkvmgvf9b1</a> </li>
<li>Kubernetes Scheduling Framework:： <a href="https://hackerain.me/2020/12/21/kubernetes/kube-scheduler-framework.html">https://hackerain.me/2020/12/21/kubernetes/kube-scheduler-framework.html</a></li>
</ul>
<h4 id="Scheduler-Framework"><a href="#Scheduler-Framework" class="headerlink" title="Scheduler Framework"></a>Scheduler Framework</h4><blockquote>
<p>看过各种调度器扩展文章，都不如自己动手实践一下，本篇文章记录一下实践细节</p>
<p>当我们看到一种新的技术方案时，总会有很多疑问，如下篇幅中会一一解答疑惑</p>
<p>本次使用的Kuberentes代码为v1.20.4，k8s集群环境为1.18.2</p>
</blockquote>
<h5 id="1-Kubernetes-调度器"><a href="#1-Kubernetes-调度器" class="headerlink" title="1  Kubernetes 调度器"></a>1  Kubernetes 调度器</h5><ol>
<li><p>Scheduler Framework与其他扩展调度器有什么区别</p>
<ul>
<li>直接修改kube-scheduler方式，维护难度太高这种不需考虑</li>
<li>比较常用的<code>调度程序扩展</code>实质是一个webhook，扩展调度器需要实现predicates和priorities方法并提供http接口，这种方式存在三个弊端，第一个是数据网络传输与数据序列化带来的调度性能下降；第二个是调度扩展点只有两个并且只能在kube-scheduler选择完毕后在执行扩展接口，第三个是一旦kube-scheduler发送http请求后，存在kube-scheduler重启、扩展程序崩溃等不可控因素，带来意外后果；</li>
<li>想想针对<code>调度程序扩展</code>存在的诸多问题重新设计调度扩展策略如何避免上述问题，如何解决调度扩展程序性能下降的问题，很自然的想到使用grpc服务在一定程度上降低网络开销及序列化开销；那扩展调度接口过少呢，依然是定义足够多的proto接口；第三个问题某个kube-scheduler与扩展调度服务意外崩溃重启呢，通过一些重试及拒绝调度的策略也基本可用</li>
<li>而Scheduler Framework却给与了我们另外的答案，直接将调度插件编译进kube-scheduler，性能自然最高、扩展点也是极多、崩溃重启数据不一致问题根本不存在；那么缺点是什么呢也是扩展调度插件编译进kube-scheduler，需要替换默认的调度器</li>
</ul>
</li>
<li><p>Scheduler Framework 实现原理</p>
<p>  2.1 这里并不会打开kube-scheduler代码细说，会介绍Framework主体实现流程</p>
<ul>
<li><p>要详细了解需要动手实现一下Scheduler 扩展调度器，如下篇幅中会一步步实现扩展调度器</p>
</li>
<li><p>换个角度思考一下，假使我们要使用Golang开发一个服务，这个服务需要很多功能扩展点而功能扩展点有其他人编写，那么怎么来设计这个程序呢？</p>
</li>
<li><p>以scheduler为例来思考一下，首先扩展点很多如pod排序、node过滤、node打分、pod节点绑定，那么我们忒首先把这些算法分类：pod排序类、node过滤类、node打分类、pod绑定类，并根据这些分类分别定义扩展方法，自然想到定义一系列的interface，让扩展者实现这些接口，将实现的struct注册到程序的调用链中</p>
<ul>
<li>这便是Pod Filter插件接口，只要实现这个接口的struct便能注册到scheduler</li>
<li>kubernetes/pkg/scheduler/framework/interface.go</li>
<li>真实Kubernetes interface设计中，将这些接口打的很碎，几乎一个函数一个接口</li>
<li>并且每个插件都需要实现Name()方法，每个插件的名称必须唯一</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> FilterPlugin <span class="keyword">interface</span> &#123;</span><br><span class="line">	Plugin</span><br><span class="line">	<span class="comment">// Filter is called by the scheduling framework.</span></span><br><span class="line">	<span class="comment">// All FilterPlugins should return &quot;Success&quot; to declare that</span></span><br><span class="line">	<span class="comment">// the given node fits the pod. If Filter doesn&#x27;t return &quot;Success&quot;</span></span><br><span class="line">	Filter(ctx context.Context, state *CycleState, pod *v1.Pod, nodeInfo *NodeInfo) *Status</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
</li>
</ol>
<ul>
<li><p>我们知道一个结构体是可以实现很多interface的，假设一个开发者开发了四个struct 名字叫A、B、C、D，都实现Filter函数，那么我们的调用方在调用这些插件时该先调用哪个呢，是不是Filter函数按照A-B-C-D顺序调用，那Score函数也按照A-B-C-D顺序调用呢；</p>
<ul>
<li>首选调用顺序需要通过通过配置文件决定，在scheduler framework启动时需要加载配置 <code>KubeSchedulerConfiguration</code></li>
<li>决定函数调用顺序的是scheduler framework启动时的配置文件，每个函数均需设定调用顺序如Filter A-B-C-D、Score函数C-B-A-D，通过这样的设计可以非常自由的设计算法函数执行顺序，假设PreBind B-D，不写的插件自然不调用</li>
<li>该配置文件名为<code>KubeSchedulerConfiguration</code>，在部署时会详细介绍该配置，这个名称看起来是个资源对象，但是在k8s集群中是查不到这个资源的</li>
</ul>
<p>2.2 至此可以梳理下，我们定义了一些列的接口并且提供了注册方法，通过链式方式执行多个注册函数，伪代码如下</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">KubeSchedulerConfiguration</span><br><span class="line">  - Filter</span><br><span class="line">    - A</span><br><span class="line">    - B</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 加载配置文件</span></span><br><span class="line">    config.load(KubeSchedulerConfiguration)</span><br><span class="line">    <span class="comment">// 注册插件A B</span></span><br><span class="line">    <span class="comment">// 根据插件中函数配置，设置插件在不同调度阶段的执行位置</span></span><br><span class="line">    register.plugins(A)</span><br><span class="line">    register.plugins(B)</span><br><span class="line">    <span class="comment">// 运行调度插件</span></span><br><span class="line">    <span class="keyword">go</span> run()</span><br><span class="line">    <span class="keyword">for</span> &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">run</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// Filter</span></span><br><span class="line">    <span class="keyword">for</span> key, <span class="function"><span class="keyword">func</span> := <span class="title">range</span> <span class="title">filter</span>.<span class="title">plugins</span></span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">func</span><span class="params">(pod, node)</span></span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h5 id="2-开发环境准备"><a href="#2-开发环境准备" class="headerlink" title="2  开发环境准备"></a>2  开发环境准备</h5><ol>
<li>如何选择测试环境及Scheduler Framework 开发版本</li>
</ol>
<ul>
<li>因为手边搭建了一个k8s 1.18.2环境，便使用这个环境进行测试，后续会搭建更多测试环境进行测试</li>
<li>Scheduler Framework选择的是kubernetes 1.20.4版本，在1.20版本之前，Scheduler Framework为v1alpha1版本，1.20为正式版本</li>
</ul>
<h5 id="3-插件开发"><a href="#3-插件开发" class="headerlink" title="3 插件开发"></a>3 插件开发</h5><h6 id="3-1-项目开发"><a href="#3-1-项目开发" class="headerlink" title="3.1 项目开发"></a>3.1 项目开发</h6><ol>
<li><p>创建项目，由于scheduler plugins依赖了很重的库(kubernetes)，最好是单独建立项目进行开发</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir scheduler</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> scheduler</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> go mod init scheduler</span></span><br></pre></td></tr></table></figure></li>
<li><p>要进行自定义调度器开发，最好找到一个参考项目</p>
<ul>
<li>sample-scheduler-framework： <a href="https://github.com/cnych/sample-scheduler-framework">https://github.com/cnych/sample-scheduler-framework</a></li>
<li>官方调度器插件实现：<a href="https://github.com/kubernetes-sigs/scheduler-plugins">https://github.com/kubernetes-sigs/scheduler-plugins</a></li>
<li>项目结构如下，这两个项目的调度器实现均是&lt;1.20</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">├── deploy</span><br><span class="line">│   ├── sample-scheduler.yaml</span><br><span class="line">│   └── test-scheduler.yaml</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── main.go</span><br><span class="line">├── pkg</span><br><span class="line">│   └── plugins</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure>
<p>main.go</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;math/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;os&quot;</span></span><br><span class="line">	<span class="string">&quot;scheduler/pkg/plugins&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">	&quot;</span>time<span class="string">&quot;</span></span><br><span class="line"><span class="string">	&quot;</span>k8s.io/component-base/logs<span class="string">&quot;</span></span><br><span class="line"><span class="string">	&quot;</span>k8s.io/kubernetes/cmd/kube-scheduler/app<span class="string">&quot;</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">func main() &#123;</span></span><br><span class="line"><span class="string">	rand.Seed(time.Now().UnixNano())</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	// Register custom plugins to the scheduler framework.</span></span><br><span class="line"><span class="string">	// Later they can consist of scheduler profile(s) and hence</span></span><br><span class="line"><span class="string">	// used by various kinds of workloads.</span></span><br><span class="line"><span class="string">	command := app.NewSchedulerCommand(</span></span><br><span class="line"><span class="string">		app.WithPlugin(plugins.Name, plugins.New),</span></span><br><span class="line"><span class="string">	)</span></span><br><span class="line"><span class="string">	logs.InitLogs()</span></span><br><span class="line"><span class="string">	defer logs.FlushLogs()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	if err := command.Execute(); err != nil &#123;</span></span><br><span class="line"><span class="string">		os.Exit(1)</span></span><br><span class="line"><span class="string">	&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>
<p>plugin.go</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> plugins</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;context&quot;</span></span><br><span class="line">	<span class="string">&quot;errors&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	v1 <span class="string">&quot;k8s.io/api/core/v1&quot;</span></span><br><span class="line">	<span class="string">&quot;k8s.io/apimachinery/pkg/runtime&quot;</span></span><br><span class="line">	lcorev1 <span class="string">&quot;k8s.io/client-go/listers/core/v1&quot;</span></span><br><span class="line">	lstoragev1 <span class="string">&quot;k8s.io/client-go/listers/storage/v1&quot;</span></span><br><span class="line">	<span class="string">&quot;k8s.io/klog/v2&quot;</span></span><br><span class="line">	<span class="string">&quot;k8s.io/kubernetes/pkg/scheduler/framework&quot;</span></span><br><span class="line">	<span class="string">&quot;sort&quot;</span></span><br><span class="line">	<span class="string">&quot;strings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插件名称</span></span><br><span class="line"><span class="keyword">const</span> Name = <span class="string">&quot;plugins&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Plugins <span class="keyword">struct</span> &#123;</span><br><span class="line">	handle    framework.Handle</span><br><span class="line">	scLister  lstoragev1.StorageClassLister</span><br><span class="line">	pvcLister lcorev1.PersistentVolumeClaimLister</span><br><span class="line">	pvLister  lcorev1.PersistentVolumeLister</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 表示此结构体实现了哪些接口，这样编译器会自动检测你是否实现了所有方法</span></span><br><span class="line"><span class="keyword">var</span> _ framework.FilterPlugin = &amp;LocalStorage&#123;&#125;</span><br><span class="line"><span class="keyword">var</span> _ framework.ScorePlugin = &amp;LocalStorage&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//type PluginFactory = func(configuration *runtime.Unknown, f FrameworkHandle) (Plugin, error)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(_ runtime.Object, handle framework.Handle)</span> <span class="params">(framework.Plugin, error)</span></span> &#123;</span><br><span class="line">	scLister := handle.SharedInformerFactory().Storage().V1().StorageClasses().Lister()</span><br><span class="line">	pvcLister := handle.SharedInformerFactory().Core().V1().PersistentVolumeClaims().Lister()</span><br><span class="line">	pvLister := handle.SharedInformerFactory().Core().V1().PersistentVolumes().Lister()</span><br><span class="line">	<span class="keyword">return</span> &amp;Plugins&#123;</span><br><span class="line">		handle:    handle,</span><br><span class="line">		pvcLister: pvcLister,</span><br><span class="line">		scLister:  scLister,</span><br><span class="line">		pvLister:  pvLister,</span><br><span class="line">	&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Plugins)</span> <span class="title">Name</span><span class="params">()</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> Name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 过滤掉不符合当前 Pod 运行条件的Node（相当于旧版本的 predicate）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Plugins)</span> <span class="title">Filter</span><span class="params">(ctx context.Context, cycleState *framework.CycleState, pod *v1.Pod, node *framework.NodeInfo)</span> *<span class="title">framework</span>.<span class="title">Status</span></span> &#123;</span><br><span class="line">	klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;filter pod: %v, node: %v&quot;</span>, pod.Name, node.Node().Name)</span><br><span class="line">    pvc, err := ls.pvcLister.PersistentVolumeClaims(pod.Namespace).Get(pvcName)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> localPvc, nodeName, err</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="keyword">if</span> rand.Intn(<span class="number">10</span>) &gt; <span class="number">5</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> framework.NewStatus(framework.UnschedulableAndUnresolvable, <span class="string">&quot;node pid resource insufficient&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">	klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;filter success pod: %v, node: %v&quot;</span>, pod.Name, node.Node().Name)</span><br><span class="line">	<span class="keyword">return</span> framework.NewStatus(framework.Success, <span class="string">&quot;&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对节点进行打分（相当于旧版本的 priorities）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Plugins)</span> <span class="title">Score</span><span class="params">(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName <span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">int64</span>, *framework.Status)</span></span> &#123;</span><br><span class="line">	klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;score pod: %v, node: %v&quot;</span>, pod.Name, nodeName)</span><br><span class="line">    score := rand.intn(<span class="number">10</span>)</span><br><span class="line">	klog.V(<span class="number">3</span>).Infof(<span class="string">&quot;score pod: %v, node: %v score %v&quot;</span>, pod.Name, nodeName, score)</span><br><span class="line">	<span class="keyword">return</span> score, framework.NewStatus(framework.Success)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ScoreExtensions of the Score plugin.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Plugins)</span> <span class="title">ScoreExtensions</span><span class="params">()</span> <span class="title">framework</span>.<span class="title">ScoreExtensions</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li><p>第一点：每一个插件都需要有一个name并且实现Name()方法，假设你要实现第二个example插件，则在pkg目录下创建example目录在该目录下实现新插件，这个意思是说每个插件建立独立的目录并且插件名称要不同；</p>
</li>
<li><p>第二点：在进行插件开发时，我们几乎无可避免的要调用k8s API，对此插件早就提供好了入口</p>
<p>framework.Handle(kubernetes/pkg/scheduler/framework/interface.go:515)</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Handle <span class="keyword">interface</span> &#123;</span><br><span class="line">	<span class="comment">// 这是一个快照，可以通过它获取节点信息</span></span><br><span class="line">	SnapshotSharedLister() SharedLister</span><br><span class="line">	....</span><br><span class="line">	<span class="comment">// k8s API</span></span><br><span class="line">	ClientSet() clientset.Interface</span><br><span class="line">	<span class="comment">// EventRecorder returns an event recorder.</span></span><br><span class="line">	EventRecorder() events.EventRecorder</span><br><span class="line">	<span class="comment">// 我们调用API通常使用这个方法，他查询的是本地cache</span></span><br><span class="line">	<span class="comment">// 使用方法就像我们上边代码中的示例</span></span><br><span class="line">	SharedInformerFactory() informers.SharedInformerFactory</span><br><span class="line">	<span class="comment">// <span class="doctag">TODO:</span> unroll the wrapped interfaces to Handle.</span></span><br><span class="line">	PreemptHandle() PreemptHandle</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>第三点：进行项目编译时，可能会报依赖错误，因为go mod 会自动引入Kubernetes最新版本，新版本的可能引入了新的依赖</p>
</li>
<li><p><a href="https://github.com/kubernetes/kubernetes/blob/v1.20.4/go.mod">https://github.com/kubernetes/kubernetes/blob/v1.20.4/go.mod</a> 参考指定版本的Kubernetes却哪个依赖补充上来</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">module scheduler</span><br><span class="line"></span><br><span class="line">go 1.15</span><br><span class="line"></span><br><span class="line">require (</span><br><span class="line">	github.com&#x2F;fsnotify&#x2F;fsnotify v1.4.9</span><br><span class="line">	github.com&#x2F;hashicorp&#x2F;golang-lru v0.5.4 &#x2F;&#x2F; indirect</span><br><span class="line">	github.com&#x2F;imdario&#x2F;mergo v0.3.9 &#x2F;&#x2F; indirect</span><br><span class="line">	github.com&#x2F;onsi&#x2F;gomega v1.10.1 &#x2F;&#x2F; indirect</span><br><span class="line">	github.com&#x2F;spf13&#x2F;viper v1.7.1</span><br><span class="line">	k8s.io&#x2F;api v0.20.4</span><br><span class="line">	k8s.io&#x2F;apimachinery v0.20.4</span><br><span class="line">	k8s.io&#x2F;client-go v0.20.4</span><br><span class="line">	k8s.io&#x2F;component-base v0.20.4</span><br><span class="line">	k8s.io&#x2F;klog&#x2F;v2 v2.5.0</span><br><span class="line">	k8s.io&#x2F;kubernetes v0.0.0-00010101000000-000000000000</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">replace (</span><br><span class="line">	k8s.io&#x2F;api &#x3D;&gt; k8s.io&#x2F;api v0.20.4</span><br><span class="line">	k8s.io&#x2F;apiextensions-apiserver &#x3D;&gt; k8s.io&#x2F;apiextensions-apiserver v0.20.4</span><br><span class="line">	k8s.io&#x2F;apimachinery &#x3D;&gt; k8s.io&#x2F;apimachinery v0.20.4</span><br><span class="line">	k8s.io&#x2F;apiserver &#x3D;&gt; k8s.io&#x2F;apiserver v0.20.4</span><br><span class="line">	k8s.io&#x2F;cli-runtime &#x3D;&gt; k8s.io&#x2F;cli-runtime v0.20.4</span><br><span class="line">	k8s.io&#x2F;client-go &#x3D;&gt; k8s.io&#x2F;client-go v0.20.4</span><br><span class="line">	k8s.io&#x2F;cloud-provider &#x3D;&gt; k8s.io&#x2F;cloud-provider v0.20.4</span><br><span class="line">	k8s.io&#x2F;cluster-bootstrap &#x3D;&gt; k8s.io&#x2F;cluster-bootstrap v0.20.4</span><br><span class="line">	k8s.io&#x2F;code-generator &#x3D;&gt; k8s.io&#x2F;code-generator v0.20.4</span><br><span class="line">	k8s.io&#x2F;component-base &#x3D;&gt; k8s.io&#x2F;component-base v0.20.4</span><br><span class="line">	k8s.io&#x2F;component-helpers &#x3D;&gt; k8s.io&#x2F;component-helpers v0.20.4</span><br><span class="line">	k8s.io&#x2F;controller-manager &#x3D;&gt; k8s.io&#x2F;controller-manager v0.20.4</span><br><span class="line">	k8s.io&#x2F;cri-api &#x3D;&gt; k8s.io&#x2F;cri-api v0.20.4</span><br><span class="line">	k8s.io&#x2F;csi-translation-lib &#x3D;&gt; k8s.io&#x2F;csi-translation-lib v0.20.4</span><br><span class="line">	k8s.io&#x2F;kube-aggregator &#x3D;&gt; k8s.io&#x2F;kube-aggregator v0.20.4</span><br><span class="line">	k8s.io&#x2F;kube-controller-manager &#x3D;&gt; k8s.io&#x2F;kube-controller-manager v0.20.4</span><br><span class="line">	k8s.io&#x2F;kube-proxy &#x3D;&gt; k8s.io&#x2F;kube-proxy v0.20.4</span><br><span class="line">	k8s.io&#x2F;kube-scheduler &#x3D;&gt; k8s.io&#x2F;kube-scheduler v0.20.4</span><br><span class="line">	k8s.io&#x2F;kubectl &#x3D;&gt; k8s.io&#x2F;kubectl v0.20.4</span><br><span class="line">	k8s.io&#x2F;kubelet &#x3D;&gt; k8s.io&#x2F;kubelet v0.20.4</span><br><span class="line">	k8s.io&#x2F;kubernetes &#x3D;&gt; k8s.io&#x2F;kubernetes v1.20.4</span><br><span class="line">	k8s.io&#x2F;legacy-cloud-providers &#x3D;&gt; k8s.io&#x2F;legacy-cloud-providers v0.20.4</span><br><span class="line">	k8s.io&#x2F;metrics &#x3D;&gt; k8s.io&#x2F;metrics v0.20.4</span><br><span class="line">	k8s.io&#x2F;mount-utils &#x3D;&gt; k8s.io&#x2F;mount-utils v0.20.4</span><br><span class="line">	k8s.io&#x2F;sample-apiserver &#x3D;&gt; k8s.io&#x2F;sample-apiserver v0.20.4</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="3-2-本地调试"><a href="#3-2-本地调试" class="headerlink" title="3.2 本地调试"></a>3.2 本地调试</h6></li>
<li><p>如果要进行本地调试，我们首先要介绍一下KubeSchedulerConfiguration配置文件</p>
</li>
<li><p>这个配置的结构体定义kube-scheduler/config/v1beta1/types.go:44</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeSchedulerConfiguration</span></span><br><span class="line"><span class="attr">leaderElection:</span></span><br><span class="line">  <span class="attr">leaderElect:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">resourceName:</span> <span class="string">plugins-scheduler</span></span><br><span class="line">  <span class="attr">resourceNamespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="string">//</span> <span class="string">本地调试时需要指定，部署到集群中这个配置就不需要了</span></span><br><span class="line"><span class="attr">clientConnection:</span></span><br><span class="line">  <span class="attr">kubeconfig:</span> <span class="string">/root/.kube/config</span></span><br><span class="line"><span class="attr">profiles:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">schedulerName:</span> <span class="string">plugins-scheduler</span></span><br><span class="line">    <span class="attr">plugins:</span></span><br><span class="line">      <span class="attr">filter:</span></span><br><span class="line">        <span class="attr">enabled:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;plugins&quot;</span></span><br><span class="line">            <span class="string">//</span> <span class="string">大部分默认算法的权重都是1，不写是0</span></span><br><span class="line">            <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">score:</span></span><br><span class="line">        <span class="attr">enabled:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;plugins&quot;</span></span><br><span class="line">            <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;exmaples&quot;</span></span><br><span class="line">            <span class="attr">weight:</span> <span class="number">2</span>      </span><br></pre></td></tr></table></figure>
<ul>
<li>本地运行</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scheduler</span><br><span class="line">--authentication-kubeconfig=/root/.kube/config</span><br><span class="line">--authorization-kubeconfig=/root/.kube/config</span><br><span class="line">--kubeconfig=/root/.kube/config</span><br><span class="line">--config=/etc/kubernetes/scheduler-config.yaml // 这个就是上边的配置文件</span><br><span class="line">--v=3</span><br></pre></td></tr></table></figure>
<ul>
<li>测试yaml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: scheduler-test</span><br><span class="line">  labels:</span><br><span class="line">    app: scheduler-test</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: scheduler-test</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: scheduler-test</span><br><span class="line">    spec:</span><br><span class="line">      &#x2F;&#x2F; 指定调度</span><br><span class="line">      schedulerName: plugins-scheduler</span><br><span class="line">      containers:</span><br><span class="line">        - name: web-server</span><br><span class="line">          image: docker.io&#x2F;library&#x2F;nginx:latest</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
</ul>
<h6 id="3-3-项目部署"><a href="#3-3-项目部署" class="headerlink" title="3.3 项目部署"></a>3.3 项目部署</h6><ul>
<li><p>Dockerfile</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.15</span>-buster AS builder</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> GO111MODULE=on CGO_ENABLED=<span class="number">0</span> GOOS=linux GOARCH=amd64 GOPROXY=https://goproxy.cn,direct</span><br><span class="line"><span class="keyword">ENV</span> WORKSPACE=/workspace/scheduler</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$WORKSPACE</span></span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> . .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> <span class="variable">$WORKSPACE</span>/cmd &amp;&amp; go build -gcflags <span class="string">&#x27;-N -l&#x27;</span> -o /tmp/test-scheduler .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.12</span></span><br><span class="line"><span class="keyword">ENV</span> WORKSPACE=/workspace/bocloud.com/cloudnative/test/scheduler</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder <span class="variable">$WORKSPACE</span>/debug/scheduler-config.yaml /etc/kubernetes</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder <span class="variable">$WORKSPACE</span>/config.json /etc/<span class="built_in">test</span>/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /tmp/test-scheduler /bin/test-scheduler</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x /bin/test-scheduler</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /bin</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;test-scheduler&quot;</span>]</span></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li>deploy.yaml</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-scheduler-clusterrole</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>, <span class="string">&quot;events&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;get&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;nodes&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;delete&quot;</span>, <span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;bindings&quot;</span>, <span class="string">&quot;pods/binding&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;pods/status&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;patch&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;replicationcontrollers&quot;</span>, <span class="string">&quot;services&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;apps&quot;</span>, <span class="string">&quot;extensions&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;replicasets&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;apps&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;statefulsets&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;policy&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;poddisruptionbudgets&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>, <span class="string">&quot;persistentvolumes&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;configmaps&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>, <span class="string">&quot;csinodes&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;coordination.k8s.io&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;leases&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;events.k8s.io&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;patch&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-scheduler-sa</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-scheduler-clusterrolebinding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-scheduler-clusterrole</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">test-scheduler-sa</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-scheduler-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">scheduler-config.yaml:</span> <span class="string">|-</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">KubeSchedulerConfiguration</span></span><br><span class="line">    <span class="attr">leaderElection:</span></span><br><span class="line">      <span class="attr">leaderElect:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">resourceName:</span>  <span class="string">test-scheduler</span></span><br><span class="line">      <span class="attr">resourceNamespace:</span> <span class="string">kube-system</span></span><br><span class="line">    <span class="attr">profiles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">schedulerName:</span> <span class="string">test-scheduler</span></span><br><span class="line">      <span class="attr">plugins:</span></span><br><span class="line">        <span class="attr">filter:</span></span><br><span class="line">          <span class="attr">enabled:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;plugins&quot;</span></span><br><span class="line">              <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">score:</span></span><br><span class="line">          <span class="attr">enabled:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;plugins</span></span><br><span class="line"><span class="string">              weight: 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: apps/v1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: test-scheduler</span></span><br><span class="line"><span class="string">  namespace: kube-system</span></span><br><span class="line"><span class="string">  labels:</span></span><br><span class="line"><span class="string">    component: test-scheduler</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 1</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    matchLabels:</span></span><br><span class="line"><span class="string">      component: test-scheduler</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        component: test-scheduler</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      serviceAccount: test-scheduler-sa</span></span><br><span class="line"><span class="string">      priorityClassName: system-cluster-critical</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">        - name: test-scheduler</span></span><br><span class="line"><span class="string">          image: docker.hub.com/test/scheduler:latest</span></span><br><span class="line"><span class="string">          imagePullPolicy: &quot;</span><span class="string">Always&quot;</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&quot;test-scheduler&quot;</span>]</span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--config=/etc/kube/scheduler-config.yaml</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">--v=3</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="string">&quot;50m&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">scheduler-config</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/kube/</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/test/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">scheduler-config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">test-scheduler-config</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">test-csi-config</span></span><br></pre></td></tr></table></figure>
<h4 id="答疑"><a href="#答疑" class="headerlink" title="答疑"></a>答疑</h4><ol>
<li><p>使用Framework 的调度器会对影响默认调度算法吗</p>
<ul>
<li>不会影响，kube-scheduler首先执行默认调度算法在执行自定义调度调度算法，这个会受<code>KubeSchedulerConfiguration</code>配置文件影响</li>
</ul>
</li>
<li><p>kube-scheduler 默认调度算法有哪些</p>
<ul>
<li><p>当进行本地调试时将日志级别设置为<code>-v=3</code>,可以观察到内置调度算法及自定义调度算法所在位置</p>
</li>
<li><p>从输出日志中可以观察到算法名称及权重，当然也可以通过源码看到默认加载的算法kuberentes/pkg/scheduler/framework/plugins/legacy_registry.go:181</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">clientConnection:</span></span><br><span class="line">  <span class="attr">acceptContentTypes:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">burst:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">contentType:</span> <span class="string">application/vnd.kubernetes.protobuf</span></span><br><span class="line">  <span class="attr">kubeconfig:</span> <span class="string">/root/.kube/config</span></span><br><span class="line">  <span class="attr">qps:</span> <span class="number">50</span></span><br><span class="line"><span class="attr">enableContentionProfiling:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">enableProfiling:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">healthzBindAddress:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">:10251</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeSchedulerConfiguration</span></span><br><span class="line"><span class="attr">leaderElection:</span></span><br><span class="line">  <span class="attr">leaderElect:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">leaseDuration:</span> <span class="string">15s</span></span><br><span class="line">  <span class="attr">renewDeadline:</span> <span class="string">10s</span></span><br><span class="line">  <span class="attr">resourceLock:</span> <span class="string">leases</span></span><br><span class="line">  <span class="attr">resourceName:</span> <span class="string">test-scheduler</span></span><br><span class="line">  <span class="attr">resourceNamespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">retryPeriod:</span> <span class="string">2s</span></span><br><span class="line"><span class="attr">metricsBindAddress:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">:10251</span></span><br><span class="line"><span class="attr">parallelism:</span> <span class="number">16</span></span><br><span class="line"><span class="attr">percentageOfNodesToScore:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">podInitialBackoffSeconds:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">podMaxBackoffSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">profiles:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">pluginConfig:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">DefaultPreemptionArgs</span></span><br><span class="line">      <span class="attr">minCandidateNodesAbsolute:</span> <span class="number">100</span></span><br><span class="line">      <span class="attr">minCandidateNodesPercentage:</span> <span class="number">10</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">DefaultPreemption</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">hardPodAffinityWeight:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">InterPodAffinityArgs</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">InterPodAffinity</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">NodeAffinityArgs</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">NodeAffinity</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">NodeResourcesFitArgs</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">NodeResourcesFit</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">NodeResourcesLeastAllocatedArgs</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">memory</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">NodeResourcesLeastAllocated</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">defaultingType:</span> <span class="string">System</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">PodTopologySpreadArgs</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">      <span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line">      <span class="attr">bindTimeoutSeconds:</span> <span class="number">600</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">VolumeBindingArgs</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">VolumeBinding</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="attr">bind:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DefaultBinder</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">filter:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeUnschedulable</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeName</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TaintToleration</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodePorts</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeResourcesFit</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeRestrictions</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">EBSLimits</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GCEPDLimits</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeVolumeLimits</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">AzureDiskLimits</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeBinding</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeZone</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">InterPodAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">plugins</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">permit:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">postBind:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">postFilter:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DefaultPreemption</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">preBind:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeBinding</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">preFilter:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeResourcesFit</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodePorts</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">InterPodAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeBinding</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">preScore:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">InterPodAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TaintToleration</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">queueSort:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PrioritySort</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">reserve:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">VolumeBinding</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">score:</span></span><br><span class="line">      <span class="attr">enabled:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeResourcesBalancedAllocation</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ImageLocality</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">InterPodAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeResourcesLeastAllocated</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodeAffinity</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">NodePreferAvoidPods</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">10000</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PodTopologySpread</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TaintToleration</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">plugins</span></span><br><span class="line">        <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">test-scheduler</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>当出现Pod调度失败等问题如何排查</p>
<ul>
<li>将日志级别设置为<code>-v=5</code>可观察到更详细的调度日志</li>
</ul>
</li>
<li><p>如何多个调度器共存，如一部分Pod使用default-scheduler,一部分Pod使用自定义调度器</p>
<ul>
<li><p><a href="https://kubernetes.io/zh/docs/reference/scheduling/config/">https://kubernetes.io/zh/docs/reference/scheduling/config/</a></p>
</li>
<li><p>如下所示，即保留了默认调度器又新增了特殊调度器，如此可以为不同服务配置不同调度器且不会出现资源视图不一致问题</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubescheduler.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeSchedulerConfiguration</span></span><br><span class="line"><span class="attr">profiles:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">schedulerName:</span> <span class="literal">no</span><span class="string">-scoring-scheduler</span></span><br><span class="line">    <span class="attr">plugins:</span></span><br><span class="line">      <span class="attr">preScore:</span></span><br><span class="line">        <span class="attr">disabled:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">      <span class="attr">score:</span></span><br><span class="line">        <span class="attr">disabled:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>kube-scheduler 是如何对node进行打分的</p>
<ul>
<li>在priorities阶段会为每个node打分，<code>分值*算法权重</code>便是该算法对该node的评分</li>
<li>分值范围0-10，一般默认算法权重为1</li>
</ul>
</li>
</ol>
<h4 id="kube-scheduler源码分析链接"><a href="#kube-scheduler源码分析链接" class="headerlink" title="kube-scheduler源码分析链接"></a>kube-scheduler源码分析链接</h4><ul>
<li>附上几篇文章了解一下吧，调度器代码研究还是要需要花点时间的</li>
<li>Kubernetes Scheduler扩展功能：<a href="https://blog.csdn.net/i_want_to_be_a_god/article/details/106969992">https://blog.csdn.net/i_want_to_be_a_god/article/details/106969992</a></li>
<li>Kuberentes 调度器源码： <a href="http://hutao.tech/k8s-source-code-analysis/core/scheduler/init.html">http://hutao.tech/k8s-source-code-analysis/core/scheduler/init.html</a></li>
<li>kube-scheduler 源码分析：<a href="https://www.huweihuang.com/kubernetes-notes/code-analysis/kube-scheduler/PrioritizeNodes.html">https://www.huweihuang.com/kubernetes-notes/code-analysis/kube-scheduler/PrioritizeNodes.html</a></li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Scheduler</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant快速搭建Kubernetes集群</title>
    <url>/2021/01/17/WinVagrantKubernetesCluster/</url>
    <content><![CDATA[<h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><ul>
<li><p>自动化搭建Kubernetes集群环境</p>
</li>
<li><p>每个集群节点挂载1..N块磁盘</p>
</li>
<li><p>能够快速搭建完成</p>
</li>
<li><p>windows 10下完成集群搭建</p>
<a id="more"></a> 

</li>
</ul>
<h4 id="基础环境-amp-amp-基础组件"><a href="#基础环境-amp-amp-基础组件" class="headerlink" title="基础环境&amp;&amp;基础组件"></a>基础环境&amp;&amp;基础组件</h4><ul>
<li>windows 10 家庭中文版</li>
<li>virtualBox 6.1.16</li>
<li>vagrant 2.2.7</li>
</ul>
<h4 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h4><ul>
<li>为了快速的构建集群，我们需要构建一个基础镜像，在这个镜像里安装了很多依赖组件</li>
<li>将指定Kubernetes版本所需要的的镜像以及二进制文件下载到本地，避免外网下载</li>
<li>github.com搜索开源的vagrantfile构建Kubernetes集群方案，进行本地化修改</li>
<li>执行构建集群测试</li>
<li>需要一个好用的Bash工具，选择的Git Bash，也不用额外安装</li>
</ul>
<h4 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h4><h5 id="安装VirtualBox和Vagrant"><a href="#安装VirtualBox和Vagrant" class="headerlink" title="安装VirtualBox和Vagrant"></a>安装VirtualBox和Vagrant</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 都是从官网下载，选择合适的版本即可</span><br><span class="line">https:&#x2F;&#x2F;www.virtualbox.org&#x2F;wiki&#x2F;Downloads</span><br><span class="line">https:&#x2F;&#x2F;www.vagrantup.com&#x2F;downloads.html</span><br></pre></td></tr></table></figure>
<h5 id="对Git-Bash稍加配置，看起来更像操作linux系统"><a href="#对Git-Bash稍加配置，看起来更像操作linux系统" class="headerlink" title="对Git Bash稍加配置，看起来更像操作linux系统"></a>对Git Bash稍加配置，看起来更像操作linux系统</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ~</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim .minttyrc</span></span><br><span class="line"></span><br><span class="line">Locale=zh_CN</span><br><span class="line">Charset=UTF-8</span><br><span class="line">Columns=120</span><br><span class="line">Rows=35</span><br><span class="line">Font=Lucida Console</span><br><span class="line">FontHeight=11</span><br><span class="line">Term=xterm-256color</span><br><span class="line">CursorType=block</span><br><span class="line">CursorBlinks=yes</span><br><span class="line">Transparency=low</span><br><span class="line">BoldAsFont=yes</span><br><span class="line">AllowBlinking=no</span><br><span class="line">Scrollbar=none</span><br><span class="line">ScrollbackLines=10000</span><br><span class="line">ClickTargetMod=off</span><br><span class="line">ComposeKey=shift</span><br><span class="line">ForegroundColour=248,248,242</span><br><span class="line">BackgroundColour=39,40,34</span><br><span class="line">CursorColour=255,255,255</span><br><span class="line">Black=39,40,34</span><br><span class="line">BoldBlack=117,113,94</span><br><span class="line">Red=249,38,114</span><br><span class="line">BoldRed=204,6,78</span><br><span class="line">Green=166,226,46</span><br><span class="line">BoldGreen=122,172,24</span><br><span class="line">Yellow=255,255,81</span><br><span class="line">BoldYellow=240,169,69</span><br><span class="line">Blue=144,255,255</span><br><span class="line">BoldBlue=33,199,233</span><br><span class="line">Magenta=174,129,255</span><br><span class="line">BoldMagenta=126,51,255</span><br><span class="line">Cyan=161,239,228</span><br><span class="line">BoldCyan=95,227,210</span><br><span class="line">White=248,248,242</span><br><span class="line">BoldWhite=249,248,245</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim .bash_profile</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Shows Git branch name <span class="keyword">in</span> prompt.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Show User @ Name (still with git branch name)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">export</span> PS1=<span class="string">&quot;\u@\h \W\[\033[32m\]\$(parse_git_branch)\[\033[00m\] $ &quot;</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Or hide User @ Name (still with git branch name)</span></span><br><span class="line">export PS1=&quot;[root@localhost \W] $ &quot;</span><br></pre></td></tr></table></figure>
<h5 id="构建基础镜像"><a href="#构建基础镜像" class="headerlink" title="构建基础镜像"></a>构建基础镜像</h5><ul>
<li><p>选择centos7.6作为基础镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 先手动下载下来，我下载的v201907.24.0</span><br><span class="line">https:&#x2F;&#x2F;app.vagrantup.com&#x2F;bento&#x2F;boxes&#x2F;centos-7.6</span><br></pre></td></tr></table></figure></li>
<li><p>制作基础镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 在下载的镜像目录操作</span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant box add centos76 centos-7.6 <span class="comment"># 若是出现问题便写成绝对路径</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant init centos76</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant up</span> </span><br><span class="line">--- 等待虚拟机启动---</span><br><span class="line">- 进入虚拟机，默认账号密码vagrant:vagrant</span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant status</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant ssh default</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置虚拟机</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo su</span></span><br><span class="line">- 更改为aliyun源</span><br><span class="line"><span class="meta">$</span><span class="bash"> mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum makecache fast</span></span><br><span class="line">- 配置kubernetes的yum源</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">EOF &gt; /etc/yum.repos.d/kubernetes.repo</span></span></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum makecache fast</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum -y update</span></span><br><span class="line">- 安装一些需要的工具</span><br><span class="line"><span class="meta">$</span><span class="bash"> yum -y install yum-utils device-mapper-persistent-data lvm2</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum makecache fast</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum -y install wget net-tools nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel wget vim ncurses-devel autoconf automake zlib-devel  python-devel epel-release openssh-server socat  ipvsadm conntrack ntpdate</span></span><br><span class="line">- 关闭防火墙</span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl stop firewalld &amp;&amp; systemctl <span class="built_in">disable</span> firewalld</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum install iptables-services -y</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> service iptables stop &amp;&amp; systemctl <span class="built_in">disable</span> iptables</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ntpdate cn.pool.ntp.org</span></span><br><span class="line">- 将同步时间加入计划任务</span><br><span class="line"><span class="meta">$</span><span class="bash"> crontab -e</span></span><br><span class="line">* */1 * * * /usr/sbin/ntpdate   cn.pool.ntp.org</span><br><span class="line">- 重启crond服务</span><br><span class="line"><span class="meta">$</span><span class="bash"> service crond restart</span></span><br><span class="line">- 永久关闭selinux</span><br><span class="line"><span class="meta">$</span><span class="bash"> sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27;</span> /etc/sysconfig/selinux</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/selinux/config</span></span><br><span class="line">- 重启生效，这个可以配置完在执行</span><br><span class="line"><span class="meta">$</span><span class="bash"> reboot -f</span></span><br><span class="line">- 关闭交换空间</span><br><span class="line"><span class="meta">$</span><span class="bash"> swapoff -a</span></span><br><span class="line">- 永久禁用，打开/etc/fstab注释掉swap那一行。</span><br><span class="line"><span class="meta">$</span><span class="bash"> sed -i <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span></span><br><span class="line">- 修改内核参数</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">EOF &gt;  etc/sysctl.d/k8s.conf</span></span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">$</span><span class="bash"> sysctl --system</span></span><br><span class="line">- 安装docker，Kubernetes依赖哪个版本Docker并不重要，所以不必后安装</span><br><span class="line"><span class="meta">$</span><span class="bash"> yum install -y docker-ce-19.03.7-3.el7</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl status docker</span></span><br><span class="line">- 修改docker配置文件</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; /etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">&#123;</span><br><span class="line"> &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line"> &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line"> &quot;log-opts&quot;: &#123;</span><br><span class="line">   &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line"> &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line"> &quot;storage-opts&quot;: [</span><br><span class="line">   &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">- 重启docker</span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl daemon-reload &amp;&amp; systemctl restart docker</span></span><br><span class="line">- 设置iptables</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span></span><br><span class="line">vm.swappiness = 0</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">&quot;&quot;&quot; &gt; /etc/sysctl.conf</span><br><span class="line"><span class="meta">$</span><span class="bash"> sysctl -p</span></span><br><span class="line"></span><br><span class="line">- 开启ipvs</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">ipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack&quot;</span><br><span class="line">for kernel_module in $&#123;ipvs_modules&#125;; do</span><br><span class="line"> /sbin/modinfo -F filename $&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"> if [ $? -eq 0 ]; then</span><br><span class="line">   /sbin/modprobe $&#123;kernel_module&#125;</span><br><span class="line"> fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span></span><br></pre></td></tr></table></figure></li>
<li><p>生成镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 清理一些缓存文件</span><br><span class="line"><span class="meta">$</span><span class="bash"> yum clean all</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> rm -rf /tmp/*</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">history</span> -c</span></span><br><span class="line">- 等待一切安装完成后，打包成镜像</span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant halt</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vagrant package --base default --output base.box报错，因为default并不是虚拟机的名字，virtualbox里可以看到他的名字</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant package --output base.box</span> </span><br><span class="line"><span class="meta">$</span><span class="bash"> vagrant box add base base.box <span class="comment"># 这样就可以使用了</span></span></span><br></pre></td></tr></table></figure>
<h5 id="收集部署包"><a href="#收集部署包" class="headerlink" title="收集部署包"></a>收集部署包</h5></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- 收集kubernetes-1.18.2版本二进制包</span><br><span class="line"><span class="meta">$</span><span class="bash"> yum -y install --downloadonly --downloaddir=k8s kubelet-1.18.2 kubeadm-1.18.2 kubectl-1.18.2</span></span><br><span class="line">- 查看依赖镜像</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubeadm config images list --kubernetes-version=v1.18.2</span></span><br><span class="line">- 收集依赖镜像，从阿里云下载</span><br><span class="line">images=(</span><br><span class="line">kube-apiserver:v1.18.2</span><br><span class="line">kube-controller-manager:v1.18.2</span><br><span class="line">kube-scheduler:v1.18.2</span><br><span class="line">kube-proxy:v1.18.2</span><br><span class="line">pause:3.2</span><br><span class="line">etcd:3.4.3-0</span><br><span class="line">coredns:1.6.7</span><br><span class="line">)</span><br><span class="line">for imageName in $&#123;images[@]&#125; ; do</span><br><span class="line">        docker pull registry.aliyuncs.com/google_containers/$imageName</span><br><span class="line">        docker tag registry.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName</span><br><span class="line">        docker rmi registry.aliyuncs.com/google_containers/$imageName</span><br><span class="line">done</span><br><span class="line">- 打包镜像(docker save)</span><br><span class="line">images/</span><br><span class="line">├── calico-cni.tar.gz</span><br><span class="line">├── calico-node.tar.gz</span><br><span class="line">├── coredns.tar.gz</span><br><span class="line">├── etcd.tar.gz</span><br><span class="line">├── kube-apiserver.tar.gz</span><br><span class="line">├── kube-controller-manager.tar.gz</span><br><span class="line">├── kube-proxy.tar.gz</span><br><span class="line">├── kube-scheduler.tar.gz</span><br><span class="line">└── pause.tar.gz</span><br></pre></td></tr></table></figure>
<h5 id="编写调试vagrantfile"><a href="#编写调试vagrantfile" class="headerlink" title="编写调试vagrantfile"></a>编写调试vagrantfile</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参考：https:&#x2F;&#x2F;exxsyseng@bitbucket.org&#x2F;exxsyseng&#x2F;k8s_centos.git</span><br></pre></td></tr></table></figure>
<h4 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h4><h5 id="Nginx服务部署"><a href="#Nginx服务部署" class="headerlink" title="Nginx服务部署"></a>Nginx服务部署</h5><ul>
<li><p>部署Nginx</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- vagrant支持目录映射，windows下目录映射需要安装额外的增强设施，并且我不太想用目录映射</span><br><span class="line">- 其二是为了最小化改动vagrantfile,当部署其他版本Kubernetes时，只要将部署包放到指定目录，vagrantfile改动包获取地址就好了</span><br><span class="line">- 从nginx官网下载nginx&#x2F;Windows-1.18.0</span><br><span class="line">https:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;download.html</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>将刚刚收集的依赖包放到指定目录，有一个网络插件calico</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /] $ cd /d/nginx-kubernetes-static/k8s-1.18.2/</span><br><span class="line">[root@localhost k8s-1.18.2] $ ll</span><br><span class="line">total 1085800</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121     13585  1月 12 14:34 calico.yaml</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  83932160  1月 12 09:56 calico-cni.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  73531392  1月 12 09:55 calico-node.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  43932160  1月 12 09:50 coredns.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121   5318270  1月  4 16:42 cri-tools-1.13.0-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121 290010624  1月 12 09:51 etcd.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121   9205578  1月  4 16:46 kubeadm-1.18.2-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121 174562304  1月 12 09:48 kube-apiserver.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121 163949568  1月 12 09:50 kube-controller-manager.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121   9995342  1月  4 16:49 kubectl-1.18.2-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  21808642  1月  4 16:55 kubelet-1.18.2-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121 118547456  1月 12 09:48 kube-proxy.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  19487362  1月  4 16:56 kubernetes-cni-0.8.7-0.x86_64.rpm</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121  96840704  1月 12 09:49 kube-scheduler.tar.gz</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121    692736  1月 12 09:50 pause.tar.gz</span><br></pre></td></tr></table></figure></li>
<li><p>关于calico</p>
<blockquote>
<p>这里有一个要注意的点，virtualbox创建的虚拟机eth0地址是10.0.2.15,这个是用来vagrant ssh 通信使用的，这个我们改不了</p>
<p>我们配置了一个私有网络进行通信，就是我们主机上Host Only网卡的Ip地址段</p>
<p>而部署完calico后，会扫描所有网卡，所有虚拟机上都有10.0.2.15这个IP地址就会导致访问不通，calico Pod无法启动</p>
<p>此时我们要指定calico要使用的私有网卡，配置如下</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- calicao.yaml中name:calico-node的DaemonSet 环境变量更改为指定网卡</span><br><span class="line">- name: IP_AUTODETECTION_METHOD</span><br><span class="line">  value: &quot;interface&#x3D;eth1&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>修改nginx.conf</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~] $ cd /d/Program\ Files\ \(x86\)/nginx-1.18.0/conf/</span><br><span class="line">[root@localhost conf] $ ls</span><br><span class="line">fastcgi.conf  fastcgi_params  koi-utf  koi-win  mime.types  nginx.conf  scgi_params  uwsgi_params  win-utf</span><br><span class="line">[root@localhost conf] $ vim nginx.conf</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        #charset koi8-r;</span><br><span class="line">        #access_log  logs/host.access.log  main;</span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">        # 增加了这么一个路径</span><br><span class="line">        location ~* /k8s &#123;</span><br><span class="line">            root D://nginx-kubernetes-static//;</span><br><span class="line">            autoindex on;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li>
<li><p>启动nginx服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- nginx 目录下操作</span><br><span class="line"><span class="meta">$</span><span class="bash"> start nginx.exe</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nginx.exe -s stop <span class="comment"># 停止nginx</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nginx.exe -t -c confg/nginx.conf <span class="comment"># 检查配置</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> nginx.exe -s reload <span class="comment"># 重新加载配置</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="第一版：不需要磁盘挂载的集群"><a href="#第一版：不需要磁盘挂载的集群" class="headerlink" title="第一版：不需要磁盘挂载的集群"></a>第一版：不需要磁盘挂载的集群</h5></li>
<li><p>目录结构</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost vagrant-cluster] $ ll</span><br><span class="line">total 17</span><br><span class="line">-rwxr-xr-x 1 antmoveh 197121 1456  1月 12 13:37 bootstrap.sh*</span><br><span class="line">-rwxr-xr-x 1 antmoveh 197121 1029  1月 13 11:51 bootstrap_kmaster.sh*</span><br><span class="line">-rwxr-xr-x 1 antmoveh 197121  220  1月 13 11:53 bootstrap_kworker.sh*</span><br><span class="line">-rw-r--r-- 1 antmoveh 197121 1570  1月 13 11:30 Vagrantfile</span><br></pre></td></tr></table></figure></li>
<li><p>Vagrantfile</p>
<blockquote>
<ul>
<li>因为我的Host-Only网卡的IP地址为192.168.56.1，所以虚拟机的私有网络使用此网段，并且固定IP</li>
<li>修改NodeCount数量便能扩展worker</li>
<li>workernode.vm.box = “base” 这个是刚刚制作的基础镜像</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> -*- mode: ruby -*-</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vi: <span class="built_in">set</span> ft=ruby :</span></span><br><span class="line"></span><br><span class="line">ENV[&#x27;VAGRANT_NO_PARALLEL&#x27;] = &#x27;yes&#x27;</span><br><span class="line"></span><br><span class="line">Vagrant.configure(2) do |config|</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> default router</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">config.vm.provision <span class="string">&quot;shell&quot;</span>,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  run: <span class="string">&quot;always&quot;</span>,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  inline: <span class="string">&quot;route del default &amp;&amp; route add default gw 192.168.56.1&quot;</span></span></span><br><span class="line"></span><br><span class="line">  config.vm.synced_folder &#x27;.&#x27;, &#x27;/vagrant&#x27;, disabled: true</span><br><span class="line"></span><br><span class="line">  config.vm.provision &quot;shell&quot;, path: &quot;bootstrap.sh&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Kubernetes Master Server</span></span><br><span class="line">  config.vm.define &quot;kmaster&quot; do |kmaster|</span><br><span class="line">    kmaster.vm.box = &quot;base&quot;</span><br><span class="line">    kmaster.vm.hostname = &quot;192.168.56.120&quot;</span><br><span class="line">    kmaster.vm.network &quot;private_network&quot;, ip: &quot;192.168.56.120&quot;</span><br><span class="line">    kmaster.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">      v.name = &quot;192.168.56.120&quot;</span><br><span class="line">      v.memory = 4096</span><br><span class="line">      v.cpus = 2</span><br><span class="line">    end</span><br><span class="line">	kmaster.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">	  v.customize [&quot;modifyvm&quot;, :id, &quot;--macaddress2&quot;, &quot;080027df863a&quot;]</span><br><span class="line">	end</span><br><span class="line">    kmaster.vm.provision &quot;shell&quot;, path: &quot;bootstrap_kmaster.sh&quot;</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  NodeCount = 2</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Kubernetes Worker Nodes</span></span><br><span class="line">  (1..NodeCount).each do |i|</span><br><span class="line">    config.vm.define &quot;kworker#&#123;i&#125;&quot; do |workernode|</span><br><span class="line">      workernode.vm.box = &quot;base&quot;</span><br><span class="line">      workernode.vm.hostname = &quot;192.168.56.12#&#123;i&#125;&quot;</span><br><span class="line">      workernode.vm.network &quot;private_network&quot;, ip: &quot;192.168.56.12#&#123;i&#125;&quot;</span><br><span class="line">      workernode.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">        v.name = &quot;192.168.56.12#&#123;i&#125;&quot;</span><br><span class="line">        v.memory = 2048</span><br><span class="line">        v.cpus = 2</span><br><span class="line">      end</span><br><span class="line">   	  #workernode.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">   	  #  v.customize [&quot;modifyvm&quot;, :id, &quot;--macaddress2&quot;, &quot;080027df863a&quot;]</span><br><span class="line">  	  #end</span><br><span class="line">      workernode.vm.provision &quot;shell&quot;, path: &quot;bootstrap_kworker.sh&quot;</span><br><span class="line">    end</span><br><span class="line">  end</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>bootstrap.sh</p>
<blockquote>
<p>这个是所有节点都执行的脚本，主要是安装kubeadm加载依赖镜像</p>
<p>wget <a href="http://192.168.56.1/k8s-1.18.2/">http://192.168.56.1/k8s-1.18.2/</a> 访问的便是Nginx服务</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> base image</span></span><br><span class="line">echo &quot;[TASK 0] base centos has install docker&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Install Kubernetes</span></span><br><span class="line">echo &quot;[TASK 1] Install Kubernetes (kubeadm, kubelet and kubectl)&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">yum install -y kubeadm-1.18.2 kubelet-1.18.2 &gt;/dev/null 2&gt;&amp;1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">yum -y install --downloadonly --downloaddir=k8s kubelet kubeadm kubectl</span></span><br><span class="line">kube=&quot;cri-tools-1.13.0-0.x86_64.rpm kubeadm-1.18.2-0.x86_64.rpm kubectl-1.18.2-0.x86_64.rpm kubelet-1.18.2-0.x86_64.rpm kubernetes-cni-0.8.7-0.x86_64.rpm&quot;</span><br><span class="line">for i in $kube;do</span><br><span class="line">  wget http://192.168.56.1/k8s-1.18.2/$i</span><br><span class="line">done</span><br><span class="line">yum -y localinstall *rpm</span><br><span class="line">rm -rf *rpm</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Start and Enable kubelet service</span></span><br><span class="line">echo &quot;[TASK 2] Enable and start kubelet service&quot;</span><br><span class="line">systemctl enable kubelet &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"><span class="meta">#</span><span class="bash">systemctl start kubelet &gt;/dev/null 2&gt;&amp;1</span></span><br><span class="line"></span><br><span class="line">echo &quot;[TASk 3] local load image&quot;</span><br><span class="line">images=&quot;calico-cni.tar.gz calico-node.tar.gz coredns.tar.gz etcd.tar.gz kube-apiserver.tar.gz kube-controller-manager.tar.gz kube-proxy.tar.gz kube-scheduler.tar.gz pause.tar.gz&quot;</span><br><span class="line">for i in $images ;do</span><br><span class="line">  wget http://192.168.56.1/k8s-1.18.2/$i</span><br><span class="line">  docker load -i $i</span><br><span class="line">  rm -rf $i</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable ssh password authentication</span></span><br><span class="line">echo &quot;[TASK 4] Enable ssh password authentication&quot;</span><br><span class="line">sed -i &#x27;s/^PasswordAuthentication no/PasswordAuthentication yes/&#x27; /etc/ssh/sshd_config</span><br><span class="line">systemctl reload sshd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Set Root password</span></span><br><span class="line">echo &quot;[TASK 5] Set root password&quot;</span><br><span class="line">echo &quot;kubeadmin&quot; | passwd --stdin root &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Update vagrant user<span class="string">&#x27;s bashrc file</span></span></span><br><span class="line">echo &quot;export TERM=xterm&quot; &gt;&gt; /etc/bashrc</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>bootstrap_kmaster.sh</p>
<blockquote>
<p>这个是master节点执行的脚本</p>
<p>执行部署kuberentes master节点</p>
<p>部署网络插件</p>
<p>启动一个HTTP服务，暴露kubejoin脚本，以便被Node获取使用</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Initialize Kubernetes</span></span><br><span class="line">echo &quot;[TASK 1] Initialize Kubernetes Cluster&quot;</span><br><span class="line">kubeadm init --kubernetes-version=v1.18.2 --apiserver-advertise-address=192.168.56.120 --pod-network-cidr=10.244.0.0/16 &gt;&gt; /root/kubeinit.log 2&gt;/dev/null</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Copy Kube admin config</span></span><br><span class="line">echo &quot;[TASK 2] Copy kube admin config to Vagrant user .kube directory&quot;</span><br><span class="line">mkdir /home/vagrant/.kube</span><br><span class="line">cp /etc/kubernetes/admin.conf /home/vagrant/.kube/config</span><br><span class="line">chown -R vagrant:vagrant /home/vagrant/.kube</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Copy Kube admin config</span></span><br><span class="line">mkdir /root/.kube</span><br><span class="line">cp /etc/kubernetes/admin.conf /root/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) /root/.kube/config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Deploy flannel network</span></span><br><span class="line">echo &quot;[TASK 3] Deploy Calico network&quot;</span><br><span class="line">su - vagrant -c &quot;kubectl create -f http://192.168.56.1/k8s-1.18.2/calico.yaml&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Generate Cluster join <span class="built_in">command</span></span></span><br><span class="line">echo &quot;[TASK 4] Generate and save cluster join command to /joincluster.sh&quot;</span><br><span class="line">kubeadm token create --print-join-command &gt; joincluster.sh</span><br><span class="line"></span><br><span class="line">echo &quot;[TASK 4] start http server&quot;</span><br><span class="line">nohup python -m &quot;SimpleHTTPServer&quot; &gt;&gt; /root/http.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li>
<li><p>bootstrap_kworker.sh</p>
<blockquote>
<p>获取kubejoin脚本，然后执行</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Join worker nodes to the Kubernetes cluster</span></span><br><span class="line">echo &quot;[TASK 1] Join node to Kubernetes Cluster&quot;</span><br><span class="line">wget http://192.168.56.120:8000/joincluster.sh</span><br><span class="line"></span><br><span class="line">cat joincluster.sh</span><br><span class="line"></span><br><span class="line">bash joincluster.sh &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>如果上边已经满足了你的需求，到这就结束了，下边就是掉坑环节了。</p>
</li>
</ul>
<h5 id="第二版：需要挂载额外磁盘的集群"><a href="#第二版：需要挂载额外磁盘的集群" class="headerlink" title="第二版：需要挂载额外磁盘的集群"></a>第二版：需要挂载额外磁盘的集群</h5><h6 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h6><ul>
<li><h6 id="为什么会有这一章？"><a href="#为什么会有这一章？" class="headerlink" title="为什么会有这一章？"></a>为什么会有这一章？</h6><blockquote>
<p>因为vagrant或者virtulbox多虚拟机磁盘挂载时存在各种各样的问题</p>
</blockquote>
</li>
<li><p>理论上磁盘挂机逻辑是怎么样的？</p>
<blockquote>
<p>在一个vagrantfile中配置多个虚拟机，每个虚拟机挂载多块盘，并且大家通用示例都是这样的</p>
</blockquote>
</li>
<li><p>Vagrantfile多个虚拟机挂载多个磁盘有什么问题？</p>
<blockquote>
<p>在vagrant up时，只有第一个启动的虚拟机挂载磁盘成功并且挂载磁盘的容器并不是设置的容量，而是其他节点应该挂载的磁盘容量，</p>
<p>第二个虚拟机便报VBOX_E_FILE_ERROR (0x80bb0004)错误，对于此错误的解释大约如下：</p>
<ol>
<li>你的磁盘扇区损坏了，建议检查磁盘</li>
<li>vagrant不能并行运行</li>
<li>virtualbox存在Bug，建议你更换匹配版本</li>
<li>你使用的windows系统，报这个错误正常</li>
</ol>
<p>尝试使用插件vagrant-persistent-storage，报其他错误，无心研究这个插件了</p>
</blockquote>
</li>
<li><p>本方案如何解决上述问题</p>
<blockquote>
<p>观察到在Vagrantfile中如果只启动一个虚拟机，无论配置挂载多少块磁盘都能成功</p>
<p>由此一个想法产生了，将vagrantfile隔离在不同目录下，每个vagrantfile配置一个虚拟机，编写一个脚本来管理这些目录</p>
</blockquote>
</li>
</ul>
<h6 id="多虚拟机挂载磁盘"><a href="#多虚拟机挂载磁盘" class="headerlink" title="多虚拟机挂载磁盘"></a>多虚拟机挂载磁盘</h6><ul>
<li><p>目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">- bootstrap.sh、bootstrap_kmaster.sh、bootstrap_kworker.sh是没有任何更改的</span><br><span class="line">- 增加了vagrant.sh脚本</span><br><span class="line">- master/Vagrantfile删除了node部分</span><br><span class="line">- work1/Vagrantfile删除了master部分，并且增加了磁盘设置</span><br><span class="line">└─vagrant-disk</span><br><span class="line">    |-vagrant.sh</span><br><span class="line">    ├─master</span><br><span class="line">    │  └─bootstrap.sh</span><br><span class="line">    │  └─bootstrap_kmaster.sh</span><br><span class="line">    │  └─Vagrantfile</span><br><span class="line">    ├─worker1</span><br><span class="line">    │  └─bootstrap.sh</span><br><span class="line">    │  └─bootstrap_kworker.sh</span><br><span class="line">    │  └─Vagrantfile</span><br><span class="line">    ├─worker2</span><br><span class="line">    │  └─bootstrap.sh  </span><br><span class="line">    │  └─bootstrap_kworker.sh   </span><br><span class="line">    │  └─Vagrantfile   </span><br><span class="line">    └─worker3</span><br><span class="line">       └─bootstrap.sh  </span><br><span class="line">       └─bootstrap_kworker.sh</span><br><span class="line">       └─Vagrantfile</span><br></pre></td></tr></table></figure></li>
<li><p>Vagrantfile</p>
<blockquote>
<p>这是worker1的脚本，修改count=2便是worker2的脚本</p>
<p>若要添加多块盘，根据注释部分依次添加就好了，注意–port依次增加最大为30</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> -*- mode: ruby -*-</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> vi: <span class="built_in">set</span> ft=ruby :</span></span><br><span class="line"></span><br><span class="line">ENV[&#x27;VAGRANT_NO_PARALLEL&#x27;] = &#x27;yes&#x27;</span><br><span class="line"></span><br><span class="line">Vagrant.configure(2) do |config|</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> default router</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">config.vm.provision <span class="string">&quot;shell&quot;</span>,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  run: <span class="string">&quot;always&quot;</span>,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  inline: <span class="string">&quot;route del default &amp;&amp; route add default gw 192.168.56.1&quot;</span></span></span><br><span class="line"></span><br><span class="line">  config.vm.synced_folder &#x27;.&#x27;, &#x27;/vagrant&#x27;, disabled: true</span><br><span class="line">  </span><br><span class="line">  config.vm.provision &quot;shell&quot;, path: &quot;bootstrap.sh&quot;</span><br><span class="line">  </span><br><span class="line">  count=1</span><br><span class="line">  config.vm.define &quot;kworker#&#123;count&#125;&quot; do |workernode|</span><br><span class="line">    workernode.vm.box = &quot;base&quot;</span><br><span class="line">    workernode.vm.hostname = &quot;192.168.56.12#&#123;count&#125;&quot;</span><br><span class="line">    workernode.vm.network &quot;private_network&quot;, ip: &quot;192.168.56.12#&#123;count&#125;&quot;</span><br><span class="line">    workernode.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">      v.name = &quot;192.168.56.12#&#123;count&#125;&quot;</span><br><span class="line">      v.memory = 2048</span><br><span class="line">      v.cpus = 2</span><br><span class="line">    end</span><br><span class="line">   	#workernode.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">   	#  v.customize [&quot;modifyvm&quot;, :id, &quot;--macaddress2&quot;, &quot;080027df863a&quot;]</span><br><span class="line"><span class="meta">  	#</span><span class="bash">end</span></span><br><span class="line">	  </span><br><span class="line">	config.vm.provider &quot;virtualbox&quot; do |p|</span><br><span class="line">	  disk=&quot;kworker#&#123;count&#125;.vdi&quot;</span><br><span class="line">      unless File.exist?(disk)</span><br><span class="line">        p.customize [&#x27;createhd&#x27;, &#x27;--filename&#x27;, disk, &#x27;--format&#x27;, &#x27;VDI&#x27;, &#x27;--size&#x27;, 20 * 1024]</span><br><span class="line">      end</span><br><span class="line">      p.customize [&#x27;storageattach&#x27;, :id, &#x27;--storagectl&#x27;, &#x27;SATA Controller&#x27;, &#x27;--port&#x27;, 1, &#x27;--device&#x27;, 0, &#x27;--type&#x27;, &#x27;hdd&#x27;, &#x27;--medium&#x27;, disk]</span><br><span class="line">      #disk=&quot;kworker#&#123;count&#125;.vdi&quot;</span><br><span class="line">      #unless File.exist?(disk)</span><br><span class="line">      #  p.customize [&#x27;createhd&#x27;, &#x27;--filename&#x27;, disk, &#x27;--format&#x27;, &#x27;VDI&#x27;, &#x27;--size&#x27;, 20 * 1024]</span><br><span class="line">      #end</span><br><span class="line">      #p.customize [&#x27;storageattach&#x27;, :id, &#x27;--storagectl&#x27;, &#x27;SATA Controller&#x27;, &#x27;--port&#x27;, 2, &#x27;--device&#x27;, 0, &#x27;--type&#x27;, &#x27;hdd&#x27;, &#x27;--medium&#x27;, disk]</span><br><span class="line">	end</span><br><span class="line">	 </span><br><span class="line">    workernode.vm.provision &quot;shell&quot;, path: &quot;bootstrap_kworker.sh&quot;</span><br><span class="line">  end  </span><br><span class="line"> </span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>vagrant.sh</p>
<blockquote>
<p>所有操作通过这个脚本执行，模仿vagrant的命令</p>
<p>若是在新加一个节点，folders在增加一个目录就行了</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">op=$1</span><br><span class="line"></span><br><span class="line">folders=&quot;master worker1 worker2 worker3&quot;</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;up&quot; ]; then</span><br><span class="line">  for i in $folders;do</span><br><span class="line">    cd $i &amp;&amp; vagrant up &amp;&amp; cd ..</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;destroy&quot; ]; then</span><br><span class="line">  for i in $folders;do</span><br><span class="line">    cd $i &amp;&amp; vagrant destroy &amp;&amp; cd ..</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;reload&quot; ]; then</span><br><span class="line">  for i in $folders;do</span><br><span class="line">    cd $i &amp;&amp; vagrant reload &amp;&amp; cd ..</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;halt&quot; ]; then</span><br><span class="line">  for i in $folders;do</span><br><span class="line">    cd $i &amp;&amp; vagrant halt &amp;&amp; cd ..</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;ssh&quot; ]; then</span><br><span class="line">    cd $2 &amp;&amp; vagrant ssh $3 &amp;&amp; cd ..</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ &quot;$op&quot; == &quot;status&quot; ]; then</span><br><span class="line">  for i in $folders;do</span><br><span class="line">    cd $i &amp;&amp; vagrant status &amp;&amp; cd ..</span><br><span class="line">  done</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li>
<li><p>测试</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./vagrant.sh up # 启动集群</span><br><span class="line">./vagrant.sh halt # 停止集群</span><br><span class="line">./vagrant.sh destroy # 销毁集群</span><br><span class="line">./vagrant.sh status # 查看集群装</span><br><span class="line">./vagrant.sh reload # 重新载入集群</span><br><span class="line">./vagrant.sh ssh worker1 kworker1 # 要先指定目录在指定虚拟机名称</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>Vagrant</tag>
        <tag>Windows</tag>
        <tag>Disk</tag>
      </tags>
  </entry>
  <entry>
    <title>存储卷指标问题排查之旅</title>
    <url>/2021/07/30/%E5%AD%98%E5%82%A8%E5%8D%B7%E6%8C%87%E6%A0%87%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E4%B9%8B%E6%97%85/</url>
    <content><![CDATA[<h4 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h4><ul>
<li>最近有小伙伴反映，使用存储驱动（比如：NFS-CSI、Ceph-CSI）创建的存储卷，在Grafana看不到其容量指标，并且Prometheus中也收集不到卷容量、使用量等指标</li>
<li>据笔者所知Grafana内置了<code>kubernetes/Persistent Volumes</code>指标模板，并且其指标数据来源于kubelet；在此之前笔者并未对kubelet metrics接口进行深入研究过，借此机会探究一下kubelet 对于存储卷指标收集的实现；</li>
</ul>
<h4 id="分析-amp-确认："><a href="#分析-amp-确认：" class="headerlink" title="分析&amp;确认："></a>分析&amp;确认：</h4><ul>
<li><p>既然小伙伴反映了问题，我们首先要看一下出现问题的环境，基本的确认列表如下：</p>
<ul>
<li>使用存储驱动（NFS-CSI、Ceph-CSI）创建了PVC并且已经绑定成功（√）</li>
<li>打开Grafana查看<code>kubernetes/Persistent Volumes</code>是否有指标，确实没有（×）</li>
<li>在Grafana查看其他的kubernetes内置指标<code>kubernetes/Compute Resources/Cluster</code>，指标正常（√）</li>
<li>在Grafana查看<code>kubernetes/Persistent Volumes</code>指标计算公式，获取指标公式（√）</li>
<li>在Prometheus查看是否已经收集到对应的指标，发现未收集到（×）</li>
<li>在Prometheus查看是否收集到kubelet其他指标，已经收集到（√）</li>
<li>在k8s集群中查看kubelet相关的<code>ServiceMonitor</code>资源，正常配置（√）</li>
<li>直接调用<a href="https://kubelet:10250/metrics%EF%BC%8C%E6%8E%A5%E5%8F%A3%E6%AD%A3%E5%B8%B8%E4%BD%86%E6%9C%AA%E8%83%BD%E8%8E%B7%E5%8F%96%E5%88%B0volume%E7%9B%B8%E5%85%B3%E6%8C%87%E6%A0%87%EF%BC%88x">https://kubelet:10250/metrics，接口正常但未能获取到volume相关指标（x</a>)</li>
</ul>
</li>
<li><p><code>kubernetes/Persistent Volumes</code>指标计算公式如下，通过名字就可以看出是kubelet暴露的指标</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(</span><br><span class="line">  sum without(instance, node) (kubelet_volume_stats_capacity_bytes&#123;cluster=&quot;&quot;, job=&quot;kubelet&quot;, namespace=&quot;&quot;, persistentvolumeclaim=&quot;&quot;&#125;)</span><br><span class="line">  sum without(instance, node) (kubelet_volume_stats_available_bytes&#123;cluster=&quot;&quot;, job=&quot;kubelet&quot;, namespace=&quot;&quot;,persistentvolumeclaim=&quot;&quot;&#125;)</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>通过上述分析我们可以得出结论：Kubelet metrics接口并未暴露volume卷相关的指标数据！</p>
</li>
<li><p>下一步自然是查看一下为何kubelet metrics接口并未暴露出volume相关指标数据</p>
</li>
</ul>
<h4 id="基本概念："><a href="#基本概念：" class="headerlink" title="基本概念："></a>基本概念：</h4><ul>
<li>Prometheus主动调用应用服务的/metrics接口来获取应用指标，在Kubernetes中通过部署CRD资源ServiceMonitor来使Prometheus operator发现需要采集指标的服务，在我们上边的检查清单中主要是确认在这个链条中哪一个环节出了问题</li>
<li>kubelet启动后默认监听 10250 端口，接收并执行 Master 发来的指令，管理 Pod 及 Pod 中的容器</li>
</ul>
<h4 id="第一道坎："><a href="#第一道坎：" class="headerlink" title="第一道坎："></a>第一道坎：</h4><ul>
<li><p>当我们直接调用kubelet接口时通常会出现如下错误</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> curl https://192.168.56.121:10250/metrics</span></span><br><span class="line">unauthorized</span><br></pre></td></tr></table></figure></li>
<li><p>这是因为kubelet开启了证书认证，通常这种情况有两种方式访问</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 第一种方式：创建kubernetes需要创建kubectl使用的admin权限证书，使用此证书可以直接访问该接口</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> curl -s --cacert /etc/kubernetes/pki/ca.pem --cert /etc/kubernetes/pki/admin.pem --key /etc/kubernetes/pki/admin-key.pem https://192.168.56.121:10250/metrics|head</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 第二种方式：使用token方式，先查看一下用于kubelet所有权限的角色</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe clusterrole system:kubelet-api-admin</span></span><br><span class="line">Name:         system:kubelet-api-admin</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate: true</span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources      Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------      -----------------  --------------  -----</span><br><span class="line">  nodes/log      []                 []              [*]</span><br><span class="line">  nodes/metrics  []                 []              [*]</span><br><span class="line">  nodes/proxy    []                 []              [*]</span><br><span class="line">  nodes/spec     []                 []              [*]</span><br><span class="line">  nodes/stats    []                 []              [*]</span><br><span class="line">  nodes          []                 []              [get list watch proxy]</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create clusterrolebinding kubelet-api-test --clusterrole=system:kubelet-api-admin --serviceaccount=default:kubelet-api-test</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> SECRET=$(kubectl get secrets | grep kubelet-api-test | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> TOKEN=$(kubectl describe secret <span class="variable">$&#123;SECRET&#125;</span> | grep -E <span class="string">&#x27;^token&#x27;</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> <span class="variable">$&#123;TOKEN&#125;</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> curl -s --cacert /etc/kubernetes/cert/ca.pem -H <span class="string">&quot;Authorization: Bearer <span class="variable">$&#123;TOKEN&#125;</span>&quot;</span> https://192.168.56.121:10250/metrics|head</span></span><br></pre></td></tr></table></figure></li>
<li><p>我们不一样，我们选第三种</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改 /var/lib/kubelet/config.yaml,直接关闭kubelet证书认证，然后重启kubelet</span></span><br><span class="line"><span class="comment"># 这样就能愉快的用浏览器访问https://192.168.56.121:10250/metrics接口了</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="attr">authentication:</span></span><br><span class="line">  <span class="attr">anonymous:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheTTL:</span> <span class="string">0s</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">x509:</span></span><br><span class="line">    <span class="attr">clientCAFile:</span> <span class="string">/etc/kubernetes/pki/ca.crt</span></span><br><span class="line"><span class="attr">authorization:</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">AlwaysAllow</span></span><br><span class="line">  <span class="attr">webhook:</span></span><br><span class="line">    <span class="attr">cacheAuthorizedTTL:</span> <span class="string">0s</span></span><br><span class="line">    <span class="attr">cacheUnauthorizedTTL:</span> <span class="string">0s</span></span><br><span class="line"></span><br><span class="line"><span class="string">````</span></span><br></pre></td></tr></table></figure></li>
<li><p>顺便一提，10250端口能访问很多资源，比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;pods、&#x2F;runningpods</span><br><span class="line">&#x2F;metrics、&#x2F;metrics&#x2F;cadvisor、&#x2F;metrics&#x2F;probes</span><br><span class="line">&#x2F;spec</span><br><span class="line">&#x2F;stats、&#x2F;stats&#x2F;container</span><br><span class="line">&#x2F;logs</span><br><span class="line">&#x2F;run&#x2F;、&#x2F;exec&#x2F;, &#x2F;attach&#x2F;, &#x2F;portForward&#x2F;, &#x2F;containerLogs&#x2F;</span><br><span class="line">更多详情：https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;blob&#x2F;master&#x2F;pkg&#x2F;kubelet&#x2F;server&#x2F;server.go#L434:3</span><br></pre></td></tr></table></figure>
<h4 id="第二道曙光："><a href="#第二道曙光：" class="headerlink" title="第二道曙光："></a>第二道曙光：</h4></li>
<li><p>通过上边几步基本上确认了是由于kubelet metrics接口未上报<code>kubelet_volume_stats-*</code>指标导致的问题，那就去google一下这个指标吧</p>
</li>
<li><p>经过多番查找kubernetes在1.8版本增加了暴露volume指标的接口：详细链接如下</p>
<ul>
<li><a href="https://github.com/google/cadvisor/issues/1702#issuecomment-381189602">https://github.com/google/cadvisor/issues/1702#issuecomment-381189602</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/commit/dac2068bbd7b3365a879cbd0a5131a0955832264?branch=dac2068bbd7b3365a879cbd0a5131a0955832264&amp;diff=split">https://github.com/kubernetes/kubernetes/commit/dac2068bbd7b3365a879cbd0a5131a0955832264?branch=dac2068bbd7b3365a879cbd0a5131a0955832264&amp;diff=split</a></li>
</ul>
</li>
<li><p>所以我们把kubernetes代码checkout到v1.21.2版本查看</p>
</li>
<li><p>关键的代码如下：</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/metrics/collectors/volume_stats.go:91</span></span><br><span class="line"><span class="comment">// CollectWithStability implements the metrics.StableCollector interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(collector *volumeStatsCollector)</span> <span class="title">CollectWithStability</span><span class="params">(ch <span class="keyword">chan</span>&lt;- metrics.Metric)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 关键就这么一句，指标均来源于当前节点上的POD</span></span><br><span class="line">    <span class="comment">// 其实这也证明了kubelet只能获取当前在它节点上挂载中的volume</span></span><br><span class="line">	podStats, err := collector.statsProvider.ListPodStats()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">     ...</span><br><span class="line">	allPVCs := sets.String&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, podStat := <span class="keyword">range</span> podStats &#123;</span><br><span class="line">		<span class="keyword">if</span> podStat.VolumeStats == <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">for</span> _, volumeStat := <span class="keyword">range</span> podStat.VolumeStats &#123;</span><br><span class="line">			pvcRef := volumeStat.PVCRef</span><br><span class="line">			<span class="keyword">if</span> pvcRef == <span class="literal">nil</span> &#123;</span><br><span class="line">                  <span class="comment">// 之所以metrics指标接口未有kubelet_volume_stats-*是因为代码执行了这一句直接跳过了；</span></span><br><span class="line">                  <span class="comment">// 怎么判断出代码走了这条路径，下边分解</span></span><br><span class="line">				<span class="comment">// ignore if no PVC reference</span></span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			pvcUniqStr := pvcRef.Namespace + <span class="string">&quot;/&quot;</span> + pvcRef.Name</span><br><span class="line">			<span class="keyword">if</span> allPVCs.Has(pvcUniqStr) &#123;</span><br><span class="line">				<span class="comment">// ignore if already collected</span></span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			addGauge(volumeStatsCapacityBytesDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.CapacityBytes))</span><br><span class="line">			addGauge(volumeStatsAvailableBytesDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.AvailableBytes))</span><br><span class="line">			addGauge(volumeStatsUsedBytesDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.UsedBytes))</span><br><span class="line">			addGauge(volumeStatsInodesDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.Inodes))</span><br><span class="line">			addGauge(volumeStatsInodesFreeDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.InodesFree))</span><br><span class="line">			addGauge(volumeStatsInodesUsedDesc, pvcRef, <span class="keyword">float64</span>(*volumeStat.InodesUsed))</span><br><span class="line">			allPVCs.Insert(pvcUniqStr)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>同样在这个文件中我们还可以看到kubelet提供了哪些有关volume的指标</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">VolumeStatsCapacityBytesKey  = <span class="string">&quot;volume_stats_capacity_bytes&quot;</span></span><br><span class="line">VolumeStatsAvailableBytesKey = <span class="string">&quot;volume_stats_available_bytes&quot;</span></span><br><span class="line">VolumeStatsUsedBytesKey      = <span class="string">&quot;volume_stats_used_bytes&quot;</span></span><br><span class="line">VolumeStatsInodesKey         = <span class="string">&quot;volume_stats_inodes&quot;</span></span><br><span class="line">VolumeStatsInodesFreeKey     = <span class="string">&quot;volume_stats_inodes_free&quot;</span></span><br><span class="line">VolumeStatsInodesUsedKey     = <span class="string">&quot;volume_stats_inodes_used&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>关于如何进行指标注册等部分代码，简单展示一下，如果写过为prometheus暴露指标的应该很容易明白</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// initializeModules will initialize internal modules that do not require the container runtime to be up.</span></span><br><span class="line"><span class="comment">// Note that the modules here must not depend on modules that are not initialized here.</span></span><br><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/kubelet.go:1323</span></span><br><span class="line"><span class="comment">// kubelet 初始化，里边包含了Prometheus metrics指标注册</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kl *Kubelet)</span> <span class="title">initializeModules</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// Prometheus metrics.</span></span><br><span class="line">	metrics.Register(</span><br><span class="line">        <span class="comment">// 通过传入参数的方式加入volume metrics</span></span><br><span class="line">		collectors.NewVolumeStatsCollector(kl),</span><br><span class="line">		collectors.NewLogMetricsCollector(kl.StatsProvider.ListPodStats),</span><br><span class="line">	)</span><br><span class="line">	metrics.SetNodeName(kl.nodeName)</span><br><span class="line">	servermetrics.Register()</span><br><span class="line">    ....</span><br><span class="line">    </span><br><span class="line">	<span class="comment">// Start resource analyzer</span></span><br><span class="line">	kl.resourceAnalyzer.Start()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/metrics/metrics.go:439</span></span><br><span class="line"><span class="comment">// Register registers all metrics.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Register</span><span class="params">(collectors ...metrics.StableCollector)</span></span> &#123;</span><br><span class="line">	<span class="comment">// Register the metrics.</span></span><br><span class="line">	registerMetrics.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		legacyregistry.MustRegister(NodeName)</span><br><span class="line">		legacyregistry.MustRegister(PodWorkerDuration)</span><br><span class="line">		legacyregistry.MustRegister(PodStartDuration)</span><br><span class="line">         ...</span><br><span class="line">        <span class="comment">// 实际上在这里注册的volume metrics，这是prometheus metrics推荐的注册方式，注册一个实现指定接口的结构体</span></span><br><span class="line">		<span class="keyword">for</span> _, collector := <span class="keyword">range</span> collectors &#123;</span><br><span class="line">			legacyregistry.CustomMustRegister(collector)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>基本的volume部分指标代码我们看完了，下面就忒验证一下为啥这段代码不产生volume指标</li>
</ul>
<h4 id="第三道坎："><a href="#第三道坎：" class="headerlink" title="第三道坎："></a>第三道坎：</h4><ul>
<li><p>如何验证上述代码的是否在工作，笔者想到的方法是启动kubelet debug一下这块运行逻辑，制定好方法就这么干</p>
</li>
<li><p>一个小插曲：拉取kubernetes代码后，里边经常有很多红色的方法，导致无法顺利跳转经过反反复复各种实验后，最终删除了kubernetes的vendor目录，配置go.mod模式后一切就OK了，顺便一提Go版本升级到了1.16</p>
</li>
<li><p>如果要Debug kubelet 首先要启动kubelet并把它加入一个kubernetes集群</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">第一步：创建一个K8s集群</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes -o wide</span></span><br><span class="line">NAME             STATUS   ROLES                  AGE   VERSION   INTERNAL-IP    </span><br><span class="line">192.168.56.120   Ready    control-plane,master   52m   v1.20.4   192.168.56.120 </span><br><span class="line">192.168.56.121   Ready    &lt;none&gt;                 49m   v1.20.4   192.168.56.121 </span><br><span class="line"></span><br><span class="line">第二步：本地开发环境为ubuntu16，需要做一些配置</span><br><span class="line">① 关闭swapoff -a</span><br><span class="line">② 开启ipv4转发</span><br><span class="line">③ 配置docker cgroupManager为systemd</span><br><span class="line">④ 关闭防火墙 等等</span><br><span class="line">⑤ 设置hostname hostnamectl 192.168.56.101，之所以如此设置是为了让各个节点可以通过hostname直接访问</span><br><span class="line">⑥ 安装kubeadm yum install kubeadm kubelet</span><br><span class="line">第三步：使用kubeadm join命令将开发环境加入集群</span><br><span class="line">kubeadm join 192.168.56.120:6443 --token 4smpu7.uji2fimas85b5fwy     --discovery-token-ca-cert-hash sha256:97de144cb013ba79ce7fc059f418e92a900944ebbba2b51c39c6ecbb08406bf2 </span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">NAME             STATUS   ROLES                  AGE   VERSION</span><br><span class="line">192.168.56.101   Ready    &lt;none&gt;                 11s   v1.21.3</span><br><span class="line">192.168.56.120   Ready    control-plane,master   63m   v1.20.4</span><br><span class="line">192.168.56.121   Ready    &lt;none&gt;                 61m   v1.20.4</span><br><span class="line"></span><br><span class="line">备注①：如果你是重复join，需要先删除/etc/kubernete/* /var/lib/kubelet/* 下的所有文件</span><br><span class="line">备注②：节点上docker的配置的cgroup使用systemd管理，在/var/lib/kubelet/config.yaml中要加入cgroupDriver: systemd配置</span><br><span class="line">备注③：这一步的join操作主要是为了生成节点kubelet证书，笔者曾实验过将其他节点的证书挪到开发环境，发现证书和节点hostname绑定，故使用这种方法生成节点证书</span><br><span class="line">备注④：如果能自定义生成节点证书可以不必这样</span><br><span class="line"></span><br><span class="line">第四步：停止kubelet，启动我们Goland中的kubelet</span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl stop kubelet &amp;&amp; systemctl <span class="built_in">disable</span> kubelet</span></span><br><span class="line"></span><br><span class="line">Goland的中需要配置一下kubelet main目录，以及启动参数，可以参考下图</span><br><span class="line">/data/gopath/src/k8s.io/kubernetes/cmd/kubelet</span><br><span class="line">--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf</span><br><span class="line">--config=/var/lib/kubelet/config.yaml</span><br><span class="line">--network-plugin=cni</span><br><span class="line">--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/antmoveh/pause:3.4.1</span><br><span class="line"></span><br><span class="line">启动后，查看集群节点</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">NAME             STATUS     ROLES                  AGE   VERSION</span><br><span class="line">192.168.56.101   Ready      &lt;none&gt;                 12m   v0.0.0-master+$Format:%H$</span><br><span class="line">192.168.56.120   Ready      control-plane,master   75m   v1.20.4</span><br><span class="line">192.168.56.121   Ready      &lt;none&gt;                 73m   v1.20.4</span><br><span class="line"></span><br><span class="line">至此我们就能愉快的debug kubelet了</span><br><span class="line"></span><br><span class="line">备注①：我给Goland分配了16G可用内存，编译起来尚好。配置差些编译时间略长</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="kubelet.png"></p>
</li>
<li><p>既然我们已经可以Debug kubelet了，我们来解决上一个问题，如何确定方法metrics执行的<code>if pvcRef == nil &#123;continue&#125;</code></p>
</li>
<li><p>通过浏览器访问<code>https://127.0.0.1:10250/metrics</code> ，不要忘了关闭kubelet的https验证</p>
</li>
<li><p>一图胜千言，直观感受一下吧，如果细心观察所有的pod的volumeStats PVCRef 其实都是nil</p>
</li>
</ul>
<p><img src="pvcref.png"></p>
<ul>
<li>那问题就转到pod的pvcRef是如何填充的？</li>
</ul>
<h4 id="第四道坎："><a href="#第四道坎：" class="headerlink" title="第四道坎："></a>第四道坎：</h4><ul>
<li><p>POD指标的获取，跟踪<code>collector.statsProvider.ListPodStats()</code>一路点进去就点到cadvisor获取指标代码</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubeletstats/cadvisor_stats_provider.go:78</span></span><br><span class="line"><span class="comment">// ListPodStats returns the stats of all the pod-managed containers.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *cadvisorStatsProvider)</span> <span class="title">ListPodStats</span><span class="params">()</span> <span class="params">([]statsapi.PodStats, error)</span></span> &#123;</span><br><span class="line">     ...</span><br><span class="line">    <span class="comment">// 这里有很多指标收集的代码，把它们省略，我们只关注收集volumeStats的部分</span></span><br><span class="line">	<span class="comment">// Add each PodStats to the result.</span></span><br><span class="line">	result := <span class="built_in">make</span>([]statsapi.PodStats, <span class="number">0</span>, <span class="built_in">len</span>(podToStats))</span><br><span class="line">	<span class="keyword">for</span> _, podStats := <span class="keyword">range</span> podToStats &#123;</span><br><span class="line">		<span class="comment">// Lookup the volume stats for each pod.</span></span><br><span class="line">		podUID := types.UID(podStats.PodRef.UID)</span><br><span class="line">		<span class="keyword">var</span> ephemeralStats []statsapi.VolumeStats</span><br><span class="line">        <span class="comment">// 在这里获取的具体某个Pod的volumeStats</span></span><br><span class="line">        <span class="comment">// 这里的代码不用细究，只是路过下边的才会涉及到如何获取volume stats</span></span><br><span class="line">		<span class="keyword">if</span> vstats, found := p.resourceAnalyzer.GetPodVolumeStats(podUID); found &#123;</span><br><span class="line">			ephemeralStats = <span class="built_in">make</span>([]statsapi.VolumeStats, <span class="built_in">len</span>(vstats.EphemeralVolumes))</span><br><span class="line">			<span class="built_in">copy</span>(ephemeralStats, vstats.EphemeralVolumes)</span><br><span class="line">			podStats.VolumeStats = <span class="built_in">append</span>(<span class="built_in">append</span>([]statsapi.VolumeStats&#123;&#125;, vstats.EphemeralVolumes...), vstats.PersistentVolumes...)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> result, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 继续点进去，就来到了</span></span><br><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/server/stats/fs_resource_analyzer.go:99</span></span><br><span class="line"><span class="comment">// 这段代码看起来异常简单，其实就是获取了一些缓存，那我们就忒观察一下这个缓存如何更新的了       </span></span><br><span class="line"><span class="comment">// GetPodVolumeStats returns the PodVolumeStats for a given pod.  Results are looked up from a cache that</span></span><br><span class="line"><span class="comment">// is eagerly populated in the background, and never calculated on the fly.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *fsResourceAnalyzer)</span> <span class="title">GetPodVolumeStats</span><span class="params">(uid types.UID)</span> <span class="params">(PodVolumeStats, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">	cache := s.cachedVolumeStats.Load().(statCache)</span><br><span class="line">	statCalc, found := cache[uid]</span><br><span class="line">	<span class="keyword">if</span> !found &#123;</span><br><span class="line">		<span class="comment">// <span class="doctag">TODO:</span> Differentiate between stats being empty</span></span><br><span class="line">		<span class="comment">// See issue #20679</span></span><br><span class="line">		<span class="keyword">return</span> PodVolumeStats&#123;&#125;, <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> statCalc.GetLatest()</span><br><span class="line">&#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure></li>
<li><p>还记得我们要查找为啥pvcRef对象是nil，就是因为这个缓存里没有！</p>
</li>
<li><p>可以脑补一下，更新这个缓存必然是需要一个goroutine，下边实际是要看这个定时goroutine是如何实现的，多长时间更新一次、从哪里获取这些指标</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简单的start函数</span></span><br><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/server/stats/fs_resource_analyzer.go:61</span></span><br><span class="line"><span class="comment">// Start eager background caching of volume stats.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *fsResourceAnalyzer)</span> <span class="title">Start</span><span class="params">()</span></span> &#123;</span><br><span class="line">	s.startOnce.Do(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="comment">// 这里要注意一下，这个时间是通过/var/lib/kubelet/config.yaml中volumeStatsAggPeriod: 30s配置的 默认为为1m0s，注意将这个值设置小于零更新指标协程还是会正常启动</span></span><br><span class="line">		<span class="keyword">if</span> s.calcPeriod &lt;= <span class="number">0</span> &#123;</span><br><span class="line">			klog.InfoS(<span class="string">&quot;Volume stats collection disabled&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span></span><br><span class="line">		&#125;</span><br><span class="line">		klog.InfoS(<span class="string">&quot;Starting FS ResourceAnalyzer&quot;</span>)</span><br><span class="line">        <span class="comment">// 只有这个方法比较关键</span></span><br><span class="line">		<span class="keyword">go</span> wait.Forever(<span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; s.updateCachedPodVolumeStats() &#125;, s.calcPeriod)</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这两个方法靠着</span></span><br><span class="line"><span class="comment">// updateCachedPodVolumeStats calculates and caches the PodVolumeStats for every Pod known to the kubelet.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *fsResourceAnalyzer)</span> <span class="title">updateCachedPodVolumeStats</span><span class="params">()</span></span> &#123;</span><br><span class="line">	oldCache := s.cachedVolumeStats.Load().(statCache)</span><br><span class="line">	newCache := <span class="built_in">make</span>(statCache)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Copy existing entries to new map, creating/starting new entries for pods missing from the cache</span></span><br><span class="line">	<span class="keyword">for</span> _, pod := <span class="keyword">range</span> s.statsProvider.GetPods() &#123;</span><br><span class="line">		<span class="keyword">if</span> value, found := oldCache[pod.GetUID()]; !found &#123;</span><br><span class="line">            <span class="comment">// 这个方法就是获取新的指标了，点击startOnce一路就会点到核心方法</span></span><br><span class="line">			newCache[pod.GetUID()] = newVolumeStatCalculator(s.statsProvider, s.calcPeriod, pod, s.eventRecorder).StartOnce()</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			newCache[pod.GetUID()] = value</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    ...</span><br><span class="line">	<span class="comment">// Update the cache reference</span></span><br><span class="line">	s.cachedVolumeStats.Store(newCache)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 点下去会找到，这个方法，这算是触及到获取指标的核心了</span></span><br><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/kubelet/server/stats/volume_stat_calculator.go:96</span></span><br><span class="line"><span class="comment">// calcAndStoreStats calculates PodVolumeStats for a given pod and writes the result to the s.latest cache.</span></span><br><span class="line"><span class="comment">// If the pod references PVCs, the prometheus metrics for those are updated with the result.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *volumeStatCalculator)</span> <span class="title">calcAndStoreStats</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// Find all Volumes for the Pod</span></span><br><span class="line">	volumes, found := s.statsProvider.ListVolumesForPod(s.pod.UID)</span><br><span class="line">	<span class="keyword">if</span> !found &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">    ...</span><br><span class="line">	<span class="comment">// Call GetMetrics on each Volume and copy the result to a new VolumeStats.FsStats</span></span><br><span class="line">	<span class="keyword">var</span> ephemeralStats []stats.VolumeStats</span><br><span class="line">	<span class="keyword">var</span> persistentStats []stats.VolumeStats</span><br><span class="line">	<span class="keyword">for</span> name, v := <span class="keyword">range</span> volumes &#123;</span><br><span class="line">        <span class="comment">// 这个就是获取真实的指标接口了，找了这么久终于找到了！</span></span><br><span class="line">        <span class="comment">// 等点击去一看 懵 ,看下图</span></span><br><span class="line">		metric, err := v.GetMetrics()</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="comment">// Expected for Volumes that don&#x27;t support Metrics</span></span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line">	...</span><br><span class="line">	<span class="comment">// Store the new stats</span></span><br><span class="line">	s.latest.Store(PodVolumeStats&#123;EphemeralVolumes: ephemeralStats,</span><br><span class="line">		PersistentVolumes: persistentStats&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>metrics的实现有这么多，这获取指标到底走的哪个方法！</li>
</ul>
<p><img src="metrics.png"></p>
<h4 id="第五道曙光："><a href="#第五道曙光：" class="headerlink" title="第五道曙光："></a>第五道曙光：</h4><ul>
<li><p>笔者曾试图在ubuntu开发环境部署存储服务进行卷挂载，如果挂载成功通过Debug方式查看到底走的哪个方法，不过遗憾的是笔者的开发环境挂卷存在各种各样问题，这就不得不导致笔者换个思路来验证</p>
</li>
<li><p>第一步：在k8s集群部署一个CSI存储服务，并部署Pod使用该存储卷，比如NFS-CSI、Ceph-CSI等</p>
</li>
<li><p>第二步：部署一个使用hostpath卷的Pod</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">task-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">manual</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">task-pv-volume</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">local</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">manual</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">hostPath:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">&quot;/mnt/volume&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">volume-test</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">volume-test</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hostpath</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="number">192.168</span><span class="number">.56</span><span class="number">.121</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hostpath</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">task-pvc</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>第三步，在所有的指标实现加上日志，比如</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/volume/metrics_nil.go:30</span></span><br><span class="line"><span class="comment">// 走这个方法表示不支持获取指标，中间我们加了一行日志</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*MetricsNil)</span> <span class="title">GetMetrics</span><span class="params">()</span> <span class="params">(*Metrics, error)</span></span> &#123;</span><br><span class="line">	fmt.Println(<span class="string">&quot;metrics not support&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> &amp;Metrics&#123;&#125;, NewNotSupportedError()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>第四步，进入<code>k8s.io/kubernetes/cmd/kubelet</code>目录下执行<code>go build .</code></li>
<li>第五步，将编译好的kubelet放到<code>192.168.56.121</code>节点上替换它的<code>/usr/bin/kubelet</code>并重启kubelet</li>
<li>第六步，很快就可以收集到kubelet日志<code>journalctl -u kubelet &gt; /tmp/kubelet.log</code>，分析查看一下我们添加的日志</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Jul 28 06:55:06 192.168.56.121 kubelet[1523]: metrics du &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;89897880-6cc6-4e57-b22a-77fd647c8a22&#x2F;etc-hosts</span><br><span class="line">Jul 28 06:55:06 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:55:06.023601432 +0000 UTC m&#x3D;+567.083508594 4096 42954248Ki 37792860Ki 1 20984Ki 21396325 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: hostpath</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: &#x2F;mnt&#x2F;volume</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: default-token-4gbq6</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;0a0a59a7-6422-483c-8ae8-3b7d3ad8795a&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;default-token-4gbq6</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: metrics_cached ?</span><br><span class="line">Jul 28 06:55:07 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:48:42.628758231 +0000 UTC m&#x3D;+183.688665397 12288 940964Ki 940952Ki 9 235241 235232 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: csi-volume</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;f8d89fbd-c759-4062-bf1a-920b45296d9f&#x2F;volumes&#x2F;kubernetes.io~csi&#x2F;pvc-8b5770ec-1b16-4c19-b97d-e7cfa8d0ceec&#x2F;mount</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: metrics csi carina.storage.io</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: I0728 06:55:43.720937    1523 clientconn.go:106] parsed scheme: &quot;&quot;</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: I0728 06:55:43.720947    1523 clientconn.go:106] scheme &quot;&quot; not registered, fallback to default scheme</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: I0728 06:55:43.721108    1523 passthrough.go:48] ccResolverWrapper: sending update to cc: &#123;[&#123;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;plugins&#x2F;csi.carina.com&#x2F;csi.sock  &lt;nil&gt; 0 &lt;nil&gt;&#125;] &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: I0728 06:55:43.721126    1523 clientconn.go:948] ClientConn switching balancer to &quot;pick_first&quot;</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:55:43.720886779 +0000 UTC m&#x3D;+604.780793954 33184Ki 7158Mi 7296608Ki 3 3584Ki 3670013 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: default-token-vnnr4</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;f8d89fbd-c759-4062-bf1a-920b45296d9f&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;default-token-vnnr4</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: metrics_cached ?</span><br><span class="line">Jul 28 06:55:43 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:51:42.633793572 +0000 UTC m&#x3D;+363.693700755 12288 940964Ki 940952Ki 9 235241 235232 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:45 192.168.56.121 kubelet[1523]: scheduler-config</span><br><span class="line">Jul 28 06:55:45 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;89897880-6cc6-4e57-b22a-77fd647c8a22&#x2F;volumes&#x2F;kubernetes.io~configmap&#x2F;scheduler-config</span><br><span class="line">Jul 28 06:55:45 192.168.56.121 kubelet[1523]: metrics_cached ?</span><br><span class="line">Jul 28 06:55:45 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:46:42.673965766 +0000 UTC m&#x3D;+63.733872957 4096 42954248Ki 37793448Ki 5 20984Ki 21396589 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: xtables-lock</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: &#x2F;run&#x2F;xtables.lock</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: metrics du&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;f8d89fbd-c759-4062-bf1a-920b45296d9f&#x2F;etc-hosts</span><br><span class="line">Jul 28 06:55:56 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:55:56.285126727 +0000 UTC m&#x3D;+617.345033890 4096 42954248Ki 37792528Ki 1 20984Ki 21396325 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: carina-csi-controller-token-dmhns</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;572f71e5-a97c-4720-974c-bbc09002fad3&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;carina-csi-controller-token-dmhns</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: metrics_cached ?</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:46:42.712326121 +0000 UTC m&#x3D;+63.772233305 12288 940964Ki 940952Ki 9 235241 235232 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: socket-dir</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;572f71e5-a97c-4720-974c-bbc09002fad3&#x2F;volumes&#x2F;kubernetes.io~empty-dir&#x2F;socket-dir</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: metrics du&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;572f71e5-a97c-4720-974c-bbc09002fad3&#x2F;volumes&#x2F;kubernetes.io~empty-dir&#x2F;socket-dir</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:56:14.346621409 +0000 UTC m&#x3D;+635.406528574 0 940964Ki 940964Ki 2 235241 235239 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:56:14.346621409 +0000 UTC m&#x3D;+635.406528574 0 940964Ki 940964Ki 2 235241 235239 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: certs</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;572f71e5-a97c-4720-974c-bbc09002fad3&#x2F;volumes&#x2F;kubernetes.io~secret&#x2F;certs</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: metrics_cached ?</span><br><span class="line">Jul 28 06:56:14 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:46:42.652734769 +0000 UTC m&#x3D;+63.712641961 8192 940964Ki 940956Ki 7 235241 235234 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:16 192.168.56.121 kubelet[1523]: metrics du &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods&#x2F;c8ab6fee-a91e-46fe-b468-71f104af1eac&#x2F;etc-hosts</span><br><span class="line">Jul 28 06:56:16 192.168.56.121 kubelet[1523]: &amp;&#123;2021-07-28 06:56:16.39212959 +0000 UTC m&#x3D;+637.452036755 4096 42954248Ki 37792548Ki 1 20984Ki 21396325 &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: host-dev</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;dev</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: log-dir</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;log&#x2F;carina</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: mountpoint-dir</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pods</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: modules</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;lib&#x2F;modules</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: host-mount</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;run&#x2F;mount</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: socket-dir</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;plugins&#x2F;csi.carina.com&#x2F;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: host-sys</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: plugin-dir</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;plugins</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: device-plugin</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;device-plugins</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: registration-dir</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;plugins_registry&#x2F;</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: metrics not support</span><br><span class="line">Jul 28 06:56:20 192.168.56.121 kubelet[1523]: &amp;&#123;0001-01-01 00:00:00 +0000 UTC &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt;&#125;</span><br></pre></td></tr></table></figure>
<p>第七步日志分析如下（因为日志较多合并的很多同类型的日志）：</p>
<table>
<thead>
<tr>
<th>metricsNil</th>
<th>cacheMetrics</th>
<th>metricsDu</th>
<th>metricsStatFs</th>
<th>metricsCsi</th>
</tr>
</thead>
<tbody><tr>
<td>/var/lib/kubelet/plugins_registry/<br/>/var/lib/kubelet/device-plugins<br/>/var/lib/kubelet/plugins<br/>/sys/fs/cgroup<br/>/var/lib/kubelet/plugins/<br/>/run/mount<br/>/lib/modules<br/>/var/lib/kubelet/pods<br/>/dev<br/>/run/xtables.lock<br/>/etc/cni/net.d<br/>/var/lib/calico<br/>/opt/cni/bin</td>
<td>configmap<br/>token<br/>secret</td>
<td>/var/lib/kubelet/pods/xxx/etc-hosts</td>
<td>无</td>
<td>csi volume</td>
</tr>
<tr>
<td>hostpath</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>经过分析日志，我们基本确认了哪些目录会采用哪个获取指标的方法，并且观察到CSI创建的volume是通过<code>metricsCsi</code>获取的指标信息</li>
<li>下边分析查看一个各个指标的实现代码，实际上都挺简单</li>
</ul>
<h4 id="第六观察代码："><a href="#第六观察代码：" class="headerlink" title="第六观察代码："></a>第六观察代码：</h4><ul>
<li><p>cacheMetrics</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/volume/metrics_cached.go:45</span></span><br><span class="line"><span class="comment">// 这个不就细究了，就是获取一下缓存，通过上边的日志可以看到 token/configmap/secret资源走这个方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(md *cachedMetrics)</span> <span class="title">GetMetrics</span><span class="params">()</span> <span class="params">(*Metrics, error)</span></span> &#123;</span><br><span class="line">	md.once.cache(<span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">		md.resultMetrics, md.resultError = md.wrapped.GetMetrics()</span><br><span class="line">		<span class="keyword">return</span> md.resultError</span><br><span class="line">	&#125;)</span><br><span class="line">	<span class="keyword">return</span> md.resultMetrics, md.resultError</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>metricsDu</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/volume/metrics_du.go:44</span></span><br><span class="line"><span class="comment">// 这个通过日志观察到，获取所有pod的/var/lib/kubelet/pods/89897880-6cc6-4e57-b22a-77fd647c8a22/etc-hosts文件状态，实际上就是host文件</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(md *metricsDu)</span> <span class="title">GetMetrics</span><span class="params">()</span> <span class="params">(*Metrics, error)</span></span> &#123;</span><br><span class="line">	metrics := &amp;Metrics&#123;Time: metav1.Now()&#125;</span><br><span class="line">	<span class="keyword">if</span> md.path == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, NewNoPathDefinedError()</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 这个就是获取指标的方法，点下去会得到执行的 nice -n 19 du -x -s -B 1 /var/xxxx/etc-hosts这条命令</span></span><br><span class="line">	err := md.runDiskUsage(metrics)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = md.runFind(metrics)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, err</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 这里使用了 unix.statfs获取文件信息</span></span><br><span class="line">	err = md.getFsInfo(metrics)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> metrics, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>metricsCSI</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/volume/csi/csi_metrics.go:53</span></span><br><span class="line"><span class="comment">// 可以看到这个实际是调用了CSI node服务获取的文件指标信息</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(mc *metricsCsi)</span> <span class="title">GetMetrics</span><span class="params">()</span> <span class="params">(*volume.Metrics, error)</span></span> &#123;</span><br><span class="line">	currentTime := metav1.Now()</span><br><span class="line">	ctx, cancel := context.WithTimeout(context.Background(), csiTimeout)</span><br><span class="line">	<span class="keyword">defer</span> cancel()</span><br><span class="line">	<span class="comment">// Get CSI client</span></span><br><span class="line">	csiClient, err := mc.csiClientGetter.Get()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">     ...</span><br><span class="line">	<span class="comment">// Get Volumestatus</span></span><br><span class="line">    <span class="comment">// 就是调用的这个方法，等会在看一下各个CSI这个方法的实现</span></span><br><span class="line">	metrics, err := csiClient.NodeGetVolumeStats(ctx, mc.volumeID, mc.targetPath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">    ...</span><br><span class="line">	<span class="comment">//set recorded time</span></span><br><span class="line">	metrics.Time = currentTime</span><br><span class="line">	<span class="keyword">return</span> metrics, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>metricsStatFS</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// k8s.io/kubernetes/pkg/volume/metrics_statfs.go:43</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(md *metricsStatFS)</span> <span class="title">GetMetrics</span><span class="params">()</span> <span class="params">(*Metrics, error)</span></span> &#123;</span><br><span class="line">	metrics := &amp;Metrics&#123;Time: metav1.Now()&#125;</span><br><span class="line">	<span class="keyword">if</span> md.path == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, NewNoPathDefinedError()</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">// 这里使用了 unix.statfs获取文件信息，和du那个实现是调用的一个方法</span></span><br><span class="line">	err := md.getFsInfo(metrics)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> metrics, err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> metrics, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>至此各个获取文件容量指标的方法就告一段落了，最后去各个CSI实现里去确认一下<code>NodeGetVolumeStats</code>的实现</p>
</li>
<li><p>Ceph-CSI:<a href="https://github.com/ceph/ceph-csi.git">https://github.com/ceph/ceph-csi.git</a></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;k8s.io/kubernetes/pkg/volume&quot;</span></span><br><span class="line"><span class="comment">// github.com/ceph/ceph-csi/internal/csi-common/nodeserver-default.go</span></span><br><span class="line"><span class="comment">// NodeGetVolumeStats returns volume stats.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ns *DefaultNodeServer)</span> <span class="title">NodeGetVolumeStats</span><span class="params">(ctx context.Context, req *csi.NodeGetVolumeStatsRequest)</span> <span class="params">(*csi.NodeGetVolumeStatsResponse, error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> err error</span><br><span class="line">	targetPath := req.GetVolumePath()</span><br><span class="line">     ...</span><br><span class="line">	isMnt, err := util.IsMountPoint(targetPath)</span><br><span class="line">    <span class="comment">// 看这里 NewMetricsStatFs，在看看上边的import,这就是kubelet获取文件指标的实现，ceph-csi实现引用了它 </span></span><br><span class="line">	cephMetricsProvider := volume.NewMetricsStatFS(targetPath)</span><br><span class="line">	volMetrics, volMetErr := cephMetricsProvider.GetMetrics()</span><br><span class="line">     ...</span><br><span class="line">	<span class="keyword">return</span> &amp;csi.NodeGetVolumeStatsResponse&#123;</span><br><span class="line">		Usage: []*csi.VolumeUsage&#123;</span><br><span class="line">			&#123;</span><br><span class="line">				Available: available,</span><br><span class="line">				Total:     capacity,</span><br><span class="line">				Used:      used,</span><br><span class="line">				Unit:      csi.VolumeUsage_BYTES,</span><br><span class="line">			&#125;,</span><br><span class="line">			&#123;</span><br><span class="line">				Available: inodesFree,</span><br><span class="line">				Total:     inodes,</span><br><span class="line">				Used:      inodesUsed,</span><br><span class="line">				Unit:      csi.VolumeUsage_INODES,</span><br><span class="line">			&#125;,</span><br><span class="line">		&#125;,</span><br><span class="line">	&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li>NFS-CSI :<a href="https://github.com/kubernetes-csi/csi-driver-nfs.git">https://github.com/kubernetes-csi/csi-driver-nfs.git</a></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;k8s.io/kubernetes/pkg/volume&quot;</span></span><br><span class="line"><span class="comment">// github.com/csi-driver-nfs/pkg/nfs/nodeserver.go:144</span></span><br><span class="line"><span class="comment">// NodeGetVolumeStats get volume stats</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ns *NodeServer)</span> <span class="title">NodeGetVolumeStats</span><span class="params">(ctx context.Context, req *csi.NodeGetVolumeStatsRequest)</span> <span class="params">(*csi.NodeGetVolumeStatsResponse, error)</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 看这里 NewMetricsStatFs，在看看上边的import,这就是kubelet获取文件指标的实现，nfs-csi实现引用了它</span></span><br><span class="line">    <span class="comment">// 和ceph-CSi获取指标的方法，一模一样；互相借鉴的吧！</span></span><br><span class="line">	volumeMetrics, err := volume.NewMetricsStatFS(req.VolumePath).GetMetrics()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, status.Errorf(codes.Internal, <span class="string">&quot;failed to get metrics: %v&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">    ...</span><br><span class="line">	<span class="keyword">return</span> &amp;csi.NodeGetVolumeStatsResponse&#123;</span><br><span class="line">		Usage: []*csi.VolumeUsage&#123;</span><br><span class="line">			&#123;</span><br><span class="line">				Unit:      csi.VolumeUsage_BYTES,</span><br><span class="line">				Available: available,</span><br><span class="line">				Total:     capacity,</span><br><span class="line">				Used:      used,</span><br><span class="line">			&#125;,</span><br><span class="line">			&#123;</span><br><span class="line">				Unit:      csi.VolumeUsage_INODES,</span><br><span class="line">				Available: inodesFree,</span><br><span class="line">				Total:     inodes,</span><br><span class="line">				Used:      inodesUsed,</span><br><span class="line">			&#125;,</span><br><span class="line">		&#125;,</span><br><span class="line">	&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="第七综述："><a href="#第七综述：" class="headerlink" title="第七综述："></a>第七综述：</h4><ul>
<li>①我们从Grafana不显示volume容量指标开始，一路追查Prometheus数据源、绕过Kubelet证书认证、跨过kubelet本地调试的坎，然后根据源码层层追查，最终一窥kubelet提供volume指标方法的全貌</li>
<li>②只有Pod使用中的卷 metrics才会返回其指标，因为kubelet首先获取当前节点上的所有pod，然后再查询其volumeStats</li>
<li>③CSI驱动提供的存储卷，获取指标实际上是由kubelet调用CSI的<code>NodeGetVolumeStats</code>方法获取的</li>
<li>④一些内置资源类型，token/configmap/secret通过cachemetrics方法获取指标</li>
<li>⑤hostpath等等一些主机目录，是不支持获取volume指标的</li>
<li>⑥metrics du指标只用于获取所有pod的etc-hosts（/var/lib/kubelet/pod/xxxxx/etc-hosts）文件的指标</li>
<li>⑦metrics statFs该方法在kubelet中并没有只用，但是各个CSI均用该方法获取的volume指标，比如NFS-CSI、Ceph-CSI</li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>storageclass</tag>
      </tags>
  </entry>
</search>
